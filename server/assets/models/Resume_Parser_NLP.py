# -*- coding: utf-8 -*-
"""resume-parser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JeBcPIFQx8uvhFZ5yBWVYHS9RZ1z8cMa

# Importing The Dependencies
"""

pip install nlp

pip install PyPDF2

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)



# Run this cell first to download ALL required NLTK data
import nltk

# Download all necessary NLTK data at once
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')

# Sometimes punkt_tab is needed separately, try downloading it
try:
    nltk.download('punkt_tab')
except:
    print("punkt_tab is not available as a separate download, will use punkt instead")

# Verify the downloads
print("NLTK resources downloaded successfully!")

"""# Resume Generator Code"""

import random
import json
from datetime import datetime, timedelta

# --------------------------
# Enhanced Data Lists for Resume Generation
# --------------------------
first_names = ["Aditya", "Rahul", "Priya", "Neha", "Vikram", "Anjali", "Arjun", "Kavita", "Rohit", "Sneha", "Amit", "Deepika",
               "Rajesh", "Pooja", "Sanjay", "Ananya", "Vivek", "Meera", "Suresh", "Divya", "Ramesh", "Geeta", "Manoj", "Sunita",
               "Nikhil", "Ritika", "Karan", "Simran", "Akash", "Isha", "Ravi", "Tanya", "Siddharth", "Preeti", "Harsh", "Swati",
               "Mohit", "Ruchi", "Gaurav", "Shweta", "Varun", "Nandini", "Kunal", "Madhuri", "Manish", "Juhi", "Prakash", "Radha",
               "Naveen", "Shilpa", "Dinesh", "Rachna", "Sachin", "Tanvi", "Vijay", "Komal", "Alok", "Manju", "Deepak", "Aarti",
               "Shreya", "Raghav", "Jatin", "Nisha", "Vishal", "Kritika", "Abhishek", "Sonam", "Sandeep", "Bhavna", "Rajiv", "Monika"]

last_names = ["Sharma", "Patel", "Singh", "Kumar", "Gupta", "Joshi", "Verma", "Yadav", "Mishra", "Reddy", "Chatterjee", "Iyer",
              "Banerjee", "Agarwal", "Mehta", "Kapoor", "Malhotra", "Nair", "Shah", "Chauhan", "Bhatia", "Thakur", "Pandey", "Jain",
              "Saxena", "Srivastava", "Rastogi", "Dubey", "Tiwari", "Bhattacharya", "Mukherjee", "Das", "Roy", "Sen", "Ghosh",
              "Dutta", "Paul", "Bose", "Chakraborty", "Khanna", "Menon", "Chopra", "Sethi", "Basu", "Khurrana", "Desai", "Patil",
              "Bajaj", "Chawla", "Hegde", "Kaur", "Vyas", "Chandra", "Mathur", "Prasad", "Arora", "Goel", "Jaggi", "Venkatesh", "Rao",
              "Trivedi", "Mahajan", "Kamath", "Dhillon", "Wadhwa", "Shinde", "Naidu", "Sharma", "Bhaskaran", "Gill", "Shroff"]

email_domains = ["gmail.com", "outlook.com", "yahoo.com", "hotmail.com", "icloud.com", "protonmail.com", "zoho.com", "aol.com",
          "mail.com", "fastmail.com", "yandex.com", "tutanota.com", "gmx.com", "rediffmail.com", "live.com", "edu.in",
          "outlook.in", "company.com", "mailinator.com", "hubspot.com"]

github_prefixes = ["code-", "dev-", "github-", "coder-", "programmer-", "tech-", "geek-", "hack-", "pro-", "master-",
                   "build-", "create-", "design-", "develop-", "engineer-", "innovate-", "script-", "webdev-", "data-",
                   "ai-", "ml-", "algo-", "logical-", "cyber-", "cloud-", "quantum-", "pixel-", "byte-", "repo-", "git-",
                   "code", "dev", "tech", "software", "sys", "full-stack", "backend", "frontend", "security", "iot",
                   "robotics", "systems", "network", "crypto", "blockchain", "web3", "pipeline", "devops", "infra"]

institutions = ["IIT Patna", "IIT Delhi", "IIT Bombay", "IIT Madras", "IIT Kanpur", "IIT Kharagpur", "IIT Roorkee", "IIT Guwahati",
                "IIT Hyderabad", "BITS Pilani", "NIT Trichy", "NIT Warangal", "NIT Surathkal", "NIT Rourkela", "NIT Calicut",
                "NIT Jaipur", "NIT Nagpur", "NIT Kurukshetra", "NIT Durgapur", "NIT Silchar", "Delhi Technological University",
                "VIT Vellore", "SRM University", "Manipal Institute of Technology", "IIIT Hyderabad", "IIIT Delhi", "IIIT Bangalore",
                "College of Engineering Pune", "Jadavpur University", "Amity University", "Thapar University", "PEC Chandigarh",
                "NSIT Delhi", "MNIT Jaipur", "MNNIT Allahabad", "ISM Dhanbad", "BIT Mesra", "IIIT Allahabad", "HBTU Kanpur",
                "Jamia Millia Islamia", "Anna University", "Osmania University", "Shri Ram College of Commerce", "R.V. College of Engineering",
                "PSG College of Technology", "Aligarh Muslim University", "Symbiosis Institute of Technology", "KIIT University",
                "Great Lakes Institute of Management", "XLRI Jamshedpur", "IIM Ahmedabad", "IIM Bangalore", "IIM Calcutta", "IIM Lucknow"]

# Engineering branches with specific degrees
engineering_branches = {
    "CSE": ["B.Tech in Computer Science", "B.Tech in Computer Science and Engineering", "B.E. in Computer Science"],
    "IT": ["B.Tech in Information Technology", "B.E. in Information Technology", "B.Tech in Information Systems"],
    "ECE": ["B.Tech in Electronics and Communication", "B.E. in Electronics Engineering", "B.Tech in VLSI Design"],
    "EE": ["B.Tech in Electrical Engineering", "B.E. in Electrical and Electronics", "B.Tech in Power Systems"],
    "Mechanical": ["B.Tech in Mechanical Engineering", "B.E. in Mechanical Engineering", "B.Tech in Industrial Engineering"],
    "Civil": ["B.Tech in Civil Engineering", "B.E. in Civil Engineering", "B.Tech in Structural Engineering"],
    "Chemical": ["B.Tech in Chemical Engineering", "B.E. in Chemical Engineering", "B.Tech in Process Engineering"],
    "Automobile": ["B.Tech in Automobile Engineering", "B.E. in Automotive Engineering"],
    "Petroleum": ["B.Tech in Petroleum Engineering", "B.E. in Petroleum & Energy Studies"],
    "Maths & Computing": ["B.Tech in Mathematics and Computing", "Integrated M.Tech in Mathematics and Computing"],
    "Design": ["B.Des in UI/UX Design", "B.Des in Product Design", "B.Tech in Design Engineering"],
    "Energy Systems": ["B.Tech in Energy Systems Engineering", "B.E. in Renewable Energy Systems"]
}

# Non-engineering degrees
other_degrees = [
    "BCA", "MCA", "BSc in Computer Science", "BSc in Mathematics", "BSc in Physics",
    "BSc in Electronics", "BSc in Statistics", "BCom", "BBA", "MBA", "MBA in Technology Management",
    "MBA in Digital Marketing", "MSc in Data Science", "MSc in AI", "MSc in Cybersecurity",
    "BSc in Economics", "BA in Economics", "BSc in Chemistry", "BSc in Biology"
]

# Combined degrees list
all_degrees = []
for branch_degrees in engineering_branches.values():
    all_degrees.extend(branch_degrees)
all_degrees.extend(other_degrees)

# Courses by branch
courses_by_branch = {
    "CSE": [
        "Data Structures and Algorithms", "Operating Systems", "Database Management Systems",
        "Computer Networks", "Software Engineering", "Machine Learning", "Artificial Intelligence",
        "Web Development", "Compiler Design", "Computer Architecture", "Distributed Systems"
    ],
    "IT": [
        "Web Technologies", "Information Security", "Database Systems", "Cloud Computing",
        "System Administration", "Network Programming", "IT Infrastructure", "Data Warehousing",
        "Business Intelligence", "IT Project Management"
    ],
    "ECE": [
        "Digital Signal Processing", "VLSI Design", "Embedded Systems", "Communication Systems",
        "Microprocessors", "Control Systems", "RF Engineering", "Antenna Design", "Wireless Communications",
        "Digital Electronics", "Semiconductor Devices"
    ],
    "EE": [
        "Power Systems", "Electric Drives", "Control Engineering", "Power Electronics",
        "High Voltage Engineering", "Electrical Machines", "Energy Conversion", "Grid Computing",
        "Renewable Energy Systems", "Microcontrollers"
    ],
    "Mechanical": [
        "Thermodynamics", "Fluid Mechanics", "Heat Transfer", "Machine Design", "Manufacturing Processes",
        "Robotics", "CAD/CAM", "Material Science", "Automobile Engineering", "Industrial Design"
    ],
    "Civil": [
        "Structural Engineering", "Geotechnical Engineering", "Transportation Engineering",
        "Environmental Engineering", "Surveying", "Hydraulics", "Construction Management",
        "Concrete Technology", "Steel Structures", "Earthquake Engineering"
    ],
    "Chemical": [
        "Chemical Process Calculations", "Transport Phenomena", "Chemical Reaction Engineering",
        "Process Control", "Plant Design", "Biochemical Engineering", "Petroleum Refining",
        "Polymer Science", "Environmental Engineering"
    ],
    "Maths & Computing": [
        "Linear Algebra", "Probability and Statistics", "Numerical Methods", "Optimization Techniques",
        "Discrete Mathematics", "Algorithms", "Computational Mathematics", "Operations Research",
        "Differential Equations", "Mathematical Modeling"
    ]
}

# Common courses across branches
common_courses = [
    "Engineering Mathematics", "Physics", "Chemistry", "Communication Skills",
    "Environmental Studies", "Entrepreneurship", "Technical Writing", "Research Methodology",
    "Project Management", "Ethics in Engineering"
]

# Math courses
math_courses = ["Calculus", "Linear Algebra", "Probability", "Statistics", "Discrete Mathematics", "Differential Equations",
                "Graph Theory", "Number Theory", "Combinatorics", "Operations Research", "Optimization Techniques",
                "Numerical Methods", "Real Analysis", "Complex Analysis", "Vector Calculus", "Topology",
                "Stochastic Processes", "Mathematical Modeling", "Game Theory", "Cryptography", "Information Theory"]

years_college = ["2023-2027", "2022-2026", "2021-2025", "2020-2024", "2019-2023", "2018-2022", "2017-2021", "2016-2020"]
years_school = ["2019", "2020", "2021", "2022", "2023", "2018", "2017", "2016", "2015"]

schools = ["Delhi Public School", "Kendriya Vidyalaya", "St. Xavier's High School", "Modern School", "DAV Public School",
           "Army Public School", "Birla Vidya Niketan", "Sanskriti School", "Amity International School", "Ryan International School",
           "Springdales School", "La Martiniere", "The Doon School", "Mayo College", "Welham Boys' School", "Welham Girls' School",
           "Scindia School", "Bishop Cotton School", "Lawrence School, Sanawar", "Vidya Mandir", "PSBB School", "Padma Seshadri School"]

cities = ["Patna", "Delhi", "Mumbai", "Chennai", "Kolkata", "Bangalore", "Hyderabad", "Pune", "Ahmedabad", "Jaipur",
          "Lucknow", "Chandigarh", "Indore", "Bhopal", "Nagpur", "Kochi", "Guwahati", "Bhubaneswar", "Dehradun", "Shimla",
          "Surat", "Vadodara", "Nashik", "Coimbatore", "Mysore", "Trivandrum", "Visakhapatnam", "Ranchi", "Siliguri", "Varanasi"]

# Enhanced project data with technical keywords by domain
project_domains = {
    "Software Development": {
        "titles": [
            "Full-Stack E-commerce Platform", "Real-time Chat Application", "Content Management System",
            "Task Management & Productivity Suite", "Custom API Development", "Social Media Platform",
            "Document Collaboration Tool", "Job Application Tracker", "Educational Learning Platform"
        ],
        "keywords": ["Java", "Python", "C++", "JavaScript", "REST APIs", "Microservices", "System Design",
                     "Spring Boot", "Django", "Node.js", "React", "Angular", "Vue.js", "OOP", "SDLC",
                     "Git", "DevOps", "Debugging", "Full-Stack", "Backend", "Frontend", "Docker", "Kubernetes"]
    },
    "Data Science & Analytics": {
        "titles": [
            "Predictive Analytics Dashboard", "Machine Learning Pipeline", "Data Visualization System",
            "Financial Data Analysis Tool", "Customer Segmentation Engine", "Recommendation System",
            "Fraud Detection System", "Sentiment Analysis Tool", "Market Research Analytics Platform"
        ],
        "keywords": ["Python", "R", "SQL", "Data Analysis", "Machine Learning", "Deep Learning", "Pandas",
                     "NumPy", "TensorFlow", "PyTorch", "Tableau", "Power BI", "Data Visualization",
                     "Big Data", "Statistical Modeling", "Predictive Analytics", "NLP", "Data Cleaning",
                     "Feature Engineering", "Regression", "Classification", "Clustering"]
    },
    "Mobile Development": {
        "titles": [
            "Fitness Tracking Application", "Food Delivery App", "Travel Planner Mobile App",
            "Mobile Payment Solution", "Social Networking App", "Healthcare Patient Portal",
            "Mobile Learning Platform", "Weather Prediction App", "Ride-sharing Service Application"
        ],
        "keywords": ["Android", "iOS", "Kotlin", "Swift", "Java", "React Native", "Flutter", "UI/UX",
                     "Firebase", "Mobile Analytics", "Push Notifications", "Offline Storage",
                     "Performance Optimization", "Cross-Platform", "App Store", "Play Store",
                     "Mobile Security", "Responsive Design"]
    },
    "AI & Machine Learning": {
        "titles": [
            "AI-powered Chatbot", "Image Recognition System", "Natural Language Processing Tool",
            "Automated Trading Algorithm", "Predictive Maintenance System", "Voice Assistant",
            "Computer Vision System", "Anomaly Detection System", "Personalized Learning AI"
        ],
        "keywords": ["AI", "ML", "Deep Learning", "NLP", "Computer Vision", "Neural Networks",
                     "TensorFlow", "PyTorch", "Keras", "Data Preprocessing", "Model Training",
                     "Feature Extraction", "Reinforcement Learning", "GPT", "BERT", "CNN", "RNN",
                     "Time Series Analysis", "Classification", "Clustering"]
    },
    "Web Development": {
        "titles": [
            "Portfolio Website", "E-commerce Store", "Blogging Platform", "Community Forum",
            "Real Estate Listing Site", "Job Board Portal", "Event Management Website",
            "Online Course Platform", "Restaurant Ordering System"
        ],
        "keywords": ["HTML", "CSS", "JavaScript", "React", "Angular", "Vue.js", "Bootstrap",
                     "Tailwind CSS", "Responsive Design", "PHP", "Node.js", "WordPress",
                     "SEO Optimization", "UI/UX", "Web Performance", "MERN Stack", "MEAN Stack",
                     "Web Accessibility", "Progressive Web Apps"]
    },
    "Cloud & DevOps": {
        "titles": [
            "AWS Serverless Application", "Containerized Microservices System", "CI/CD Pipeline Implementation",
            "Cloud Migration Strategy", "Infrastructure as Code Framework", "Auto-scaling Cloud Solution",
            "Multi-Cloud Management System", "DevSecOps Implementation", "Distributed Logging System"
        ],
        "keywords": ["AWS", "Azure", "GCP", "Docker", "Kubernetes", "Terraform", "Jenkins", "GitHub Actions",
                     "CircleCI", "Ansible", "Puppet", "Chef", "Prometheus", "Grafana", "ELK Stack",
                     "Serverless", "Microservices", "Infrastructure as Code", "CI/CD", "DevOps", "Site Reliability"]
    },
    "Cybersecurity": {
        "titles": [
            "Network Security Analysis Tool", "Security Compliance Automation", "Vulnerability Assessment Framework",
            "Intrusion Detection System", "Secure Authentication System", "Data Encryption Framework",
            "Security Audit Tool", "Penetration Testing Framework", "Secure Coding Practices Guide"
        ],
        "keywords": ["Cybersecurity", "Network Security", "Penetration Testing", "Ethical Hacking", "SIEM",
                     "Encryption", "Authentication", "Authorization", "Firewall", "IDS/IPS", "Malware Analysis",
                     "Security Audit", "Compliance", "Risk Assessment", "Secure Coding", "Security Protocols",
                     "Digital Forensics", "Threat Modeling", "Zero Trust", "Security Operations"]
    },
    "IoT & Embedded Systems": {
        "titles": [
            "Smart Home Automation System", "Industrial IoT Monitoring", "Wearable Health Tracker",
            "Environmental Monitoring System", "Agricultural Automation System", "Smart Building Management",
            "Fleet Management IoT Solution", "Retail IoT Analytics Platform", "Energy Management System"
        ],
        "keywords": ["IoT", "Embedded C", "Arduino", "Raspberry Pi", "MQTT", "Sensors", "Actuators",
                     "Microcontrollers", "FPGA", "Wireless Communication", "BLE", "RFID", "NFC",
                     "Edge Computing", "Power Optimization", "Real-time Systems", "Firmware Development",
                     "Hardware-Software Integration", "Prototyping", "PCB Design"]
    },
    "Blockchain & Fintech": {
        "titles": [
            "Cryptocurrency Wallet", "Smart Contract Application", "Decentralized Finance (DeFi) Platform",
            "Blockchain Supply Chain Tracker", "NFT Marketplace", "Identity Verification System",
            "Tokenization Platform", "Crypto Trading Bot", "Blockchain Voting System"
        ],
        "keywords": ["Blockchain", "Ethereum", "Solidity", "Smart Contracts", "Web3.js", "Cryptocurrency",
                     "Bitcoin", "DeFi", "NFT", "Cryptography", "Consensus Algorithms", "Distributed Ledger",
                     "Tokenization", "Wallets", "Public Key Infrastructure", "Private/Public Keys",
                     "Hyperledger", "Solana", "Truffle", "Hardhat"]
    },
    "Mechanical & Automotive": {
        "titles": [
            "Vehicle Dynamics Simulation", "CAD Model Optimization", "Manufacturing Process Automation",
            "Thermal System Design", "Robotic Process Automation", "Industrial Equipment Design",
            "Vehicle Performance Analysis", "Mechanical Testing System", "CNC Programming Tool"
        ],
        "keywords": ["CAD", "SolidWorks", "AutoCAD", "Vehicle Dynamics", "Thermodynamics", "Fluid Mechanics",
                     "MATLAB", "Robotics", "Process Automation", "CNC", "3D Printing", "Prototyping",
                     "Material Testing", "Product Development", "Manufacturing", "Mechanical Design",
                     "Industrial Automation", "Simulation", "ANSYS", "Finite Element Analysis"]
    },
    "Electrical & Energy Systems": {
        "titles": [
            "Power Distribution Optimization", "Renewable Energy Management", "Smart Grid Implementation",
            "Energy Efficiency Audit System", "Power Quality Analysis Tool", "Solar Power Monitoring",
            "Electric Vehicle Charging System", "Energy Consumption Analytics", "Battery Management System"
        ],
        "keywords": ["Power Systems", "Electrical Engineering", "Control Systems", "MATLAB", "SCADA",
                     "Renewable Energy", "Smart Grid", "Energy Management", "Circuit Design", "Power Electronics",
                     "Microcontrollers", "IoT", "Electric Vehicles", "Energy Storage", "Simulation",
                     "Power Quality", "Energy Efficiency", "Solar Power", "Wind Energy", "Grid Computing"]
    },
    "Civil & Construction": {
        "titles": [
            "Structural Analysis Tool", "Construction Management System", "Building Information Modeling",
            "Environmental Impact Assessment", "Transportation Planning Software", "Geotechnical Analysis",
            "Urban Planning Tool", "Water Resource Management", "Sustainable Building Design System"
        ],
        "keywords": ["Structural Design", "AutoCAD", "Civil 3D", "Construction Management", "BIM",
                     "Environmental Engineering", "Geotechnical Engineering", "Transportation Engineering",
                     "Urban Planning", "Sustainable Design", "Water Resources", "STAAD Pro", "ETABS",
                     "GIS", "Surveying", "Material Testing", "Project Planning", "Safety Management",
                     "Cost Estimation", "Quality Control"]
    },
    "Chemical & Process Engineering": {
        "titles": [
            "Chemical Process Simulation", "Process Optimization Tool", "Reaction Kinetics Analysis",
            "Chemical Plant Design", "Waste Treatment System", "Oil & Gas Pipeline Monitoring",
            "Pharmaceutical Process Control", "Polymer Manufacturing Optimization", "Quality Control System"
        ],
        "keywords": ["Chemical Simulation", "MATLAB", "Oil & Gas", "Process Engineering", "Aspen Plus",
                     "CHEMCAD", "Process Control", "Process Safety", "Reaction Engineering", "Heat Transfer",
                     "Mass Transfer", "Thermodynamics", "Pollution Control", "Industrial Chemistry",
                     "Petroleum Engineering", "Polymer Science", "Plant Design", "Safety Analysis",
                     "Quality Control", "Computational Fluid Dynamics"]
    },
    "Finance & Risk Management": {
        "titles": [
            "Portfolio Optimization Tool", "Risk Assessment Framework", "Financial Analysis Dashboard",
            "Credit Risk Modeling System", "Trading Algorithm", "Investment Analysis Platform",
            "Financial Fraud Detection", "Budget Forecasting Tool", "Banking Compliance System"
        ],
        "keywords": ["Finance", "Python", "SQL", "Risk Analysis", "Financial Modeling", "Excel",
                     "Credit Risk", "Investment Banking", "Data Analysis", "Risk Assessment",
                     "Quantitative Analysis", "Trading", "Financial Consulting", "Business Analysis",
                     "Banking", "Compliance", "Budget Forecasting", "Financial Planning", "Risk Management",
                     "Portfolio Management"]
    },
    "Business & Consulting": {
        "titles": [
            "Business Process Automation", "Market Analysis Dashboard", "Strategic Planning Framework",
            "Customer Relationship Management", "Sales Analytics Platform", "Digital Transformation Strategy",
            "Supply Chain Optimization", "Performance Metrics System", "Revenue Optimization Tool"
        ],
        "keywords": ["Business Analysis", "Excel", "Power BI", "Data Visualization", "Tableau", "SQL",
                     "Business Operations", "Process Improvement", "Digital Transformation", "Consulting",
                     "Market Research", "Strategic Planning", "CRM", "Sales Strategies", "Project Management",
                     "Change Management", "Supply Chain", "Performance Metrics", "Revenue Optimization",
                     "Operational Efficiency"]
    }
}

# Combine all project titles and keywords
project_titles = []
project_keywords = []
for domain in project_domains.values():
    project_titles.extend(domain["titles"])
    project_keywords.extend(domain["keywords"])

project_titles = list(set(project_titles))
project_keywords = list(set(project_keywords))

# Enhanced project descriptions with quantifiable metrics
project_descriptions = [
    "Developed a scalable solution processing over 1,000 user requests daily with 98% accuracy.",
    "Designed and implemented a responsive interface reducing page load time by 45% and increasing user retention by 28%.",
    "Optimized database queries leading to 60% faster response times and 40% reduced server load.",
    "Created a microservices architecture supporting 10,000+ concurrent users with 99.9% uptime.",
    "Built a real-time data pipeline processing 2TB of data monthly with sub-second latency.",
    "Implemented machine learning algorithms improving prediction accuracy from 76% to 91%.",
    "Developed a mobile application achieving 50,000+ downloads within first quarter of release.",
    "Engineered a security system that reduced vulnerability incidents by 75% year-over-year.",
    "Built an automated testing framework increasing code coverage from 65% to 92%.",
    "Created a recommendation engine increasing customer conversion rate by 32%.",
    "Designed an IoT system that reduced energy consumption by 40% in smart buildings.",
    "Implemented a blockchain solution that improved supply chain transparency by 65%.",
    "Developed an AI-powered analytics platform that processed 500,000+ data points daily.",
    "Built a cloud-native application with 99.99% availability and 45% reduced operational costs.",
    "Created an automated CI/CD pipeline reducing deployment time from hours to minutes.",
    "Engineered a distributed system capable of handling 2 million transactions per day.",
    "Developed a cross-platform application with 95% code reuse across Android and iOS.",
    "Implemented a financial prediction system with 87% accuracy in market trend forecasting.",
    "Built a simulation model that optimized manufacturing processes by 35%.",
    "Created an energy management system that reduced power consumption costs by 30%."
]

project_impacts = [
    "Increased user engagement by", "Improved system efficiency by", "Reduced operational costs by",
    "Boosted conversion rates by", "Enhanced customer satisfaction by", "Accelerated development cycle by",
    "Decreased error rates by", "Improved data processing speed by", "Strengthened security measures by",
    "Expanded market reach by", "Reduced carbon footprint by", "Increased revenue by",
    "Decreased customer churn by", "Improved team productivity by", "Reduced manual effort by"
]

project_impact_metrics = [
    "15-35%", "20-50%", "$10K-$50K annually", "2-5x", "10-30 percentage points",
    "40-70%", "3-6 months", "25-45%", "$100K+ in first year", "5-10x"
]

# Tools and Technology Data - Branch-specific and interbranch
tools_tech = {
    "Languages": ["Python", "Java", "C++", "JavaScript", "TypeScript", "Rust", "Go", "Ruby", "Swift", "Kotlin", "PHP", "C#", "Scala", "R", "Julia", "Dart", "Elixir", "Haskell", "C", "MATLAB"],

    "Web Frontend": ["HTML5", "CSS3", "SASS/SCSS", "React", "Angular", "Vue.js", "Next.js", "Gatsby", "Redux", "jQuery", "Bootstrap", "Tailwind CSS", "Material UI", "Styled Components", "WebGL", "Three.js", "D3.js", "Svelte"],

    "Web Backend": ["Node.js", "Express.js", "Django", "Flask", "Ruby on Rails", "Spring Boot", "ASP.NET Core", "Laravel", "FastAPI", "NestJS", "GraphQL", "REST API", "gRPC", "WebSockets"],

    "Mobile": ["React Native", "Flutter", "Android SDK", "iOS SDK", "Xamarin", "Ionic", "Kotlin Multiplatform", "SwiftUI", "Jetpack Compose", "Unity Mobile"],

    "Data Science": ["TensorFlow", "PyTorch", "scikit-learn", "Keras", "Pandas", "NumPy", "SciPy", "Matplotlib", "Seaborn", "Plotly", "NLTK", "spaCy", "Hugging Face", "XGBoost", "LightGBM", "Dask", "PySpark", "Ray"],

    "Database": ["MySQL", "PostgreSQL", "MongoDB", "Redis", "Cassandra", "DynamoDB", "Neo4j", "Elasticsearch", "SQLite", "Firebase", "Oracle", "SQL Server", "Supabase", "InfluxDB", "TimescaleDB", "Snowflake", "BigQuery"],

    "DevOps": ["Docker", "Kubernetes", "AWS", "GCP", "Azure", "Jenkins", "GitHub Actions", "CircleCI", "Travis CI", "Terraform", "Ansible", "Prometheus", "Grafana", "ELK Stack", "Pulumi", "Argo CD", "Chef", "Puppet"],

    "Blockchain": ["Ethereum", "Solidity", "Web3.js", "Hardhat", "Truffle", "Smart Contracts", "IPFS", "Chainlink", "Polkadot", "Solana", "Hyperledger"],

    "Testing": ["Jest", "Mocha", "Cypress", "Selenium", "JUnit", "PyTest", "TestNG", "Robot Framework", "Postman", "Cucumber", "Jasmine", "PHPUnit", "XCTest"],

    "CAD & Engineering": ["AutoCAD", "SolidWorks", "CATIA", "Fusion 360", "ANSYS", "Revit", "SketchUp", "Civil 3D", "STAAD Pro", "ETABS", "Altium Designer", "Eagle PCB", "Quartus Prime", "COMSOL"],

    "Electrical & IoT": ["Arduino", "Raspberry Pi", "MQTT", "PLC", "SCADA", "Verilog", "VHDL", "LabVIEW", "Embedded C", "ZigBee", "Modbus", "KiCad", "Proteus", "FlexSim"],

    "Chemical & Process": ["Aspen Plus", "CHEMCAD", "HYSYS", "gPROMS", "COMSOL", "SuperPro Designer", "DWSIM", "Pro/II", "MATLAB", "Simulink", "UniSim Design"]
}

# Branch-specific skills
branch_specific_skills = {
    "CSE": ["Algorithm Design", "Data Structures", "Software Architecture", "Web Development", "Database Management",
            "API Design", "Scalable Systems", "Network Programming", "OS Internals", "Compiler Design",
            "Cloud Computing", "Distributed Systems", "Mobile Development", "UI/UX Implementation"],

    "IT": ["System Administration", "Network Management", "Cloud Services", "IT Infrastructure",
           "Information Security", "Business Intelligence", "Enterprise Systems", "Data Management",
           "IT Service Management", "Enterprise Architecture", "System Integration"],

    "ECE": ["Digital Circuit Design", "VLSI", "Signal Processing", "Communication Protocols",
            "Embedded Systems", "PCB Design", "RF Engineering", "Wireless Communications",
            "Digital Electronics", "Microprocessor Architecture", "Control Systems"],

    "EE": ["Power Systems", "Control Engineering", "Electric Drives", "Power Electronics",
           "High Voltage Engineering", "Electrical Machines", "Grid Computing", "Energy Conversion",
           "Renewable Energy Systems", "Microcontroller Programming"],

    "Mechanical": ["Thermodynamics", "Fluid Mechanics", "Heat Transfer", "Machine Design",
                  "CAD/CAM", "Robotics", "Manufacturing Processes", "Material Science",
                  "Structural Analysis", "Vehicle Dynamics", "Industrial Automation"],

    "Civil": ["Structural Analysis", "Construction Management", "Geotechnical Engineering",
              "Transportation Engineering", "Hydraulics", "Surveying", "Environmental Engineering",
              "Building Information Modeling", "Construction Materials", "Urban Planning"],

    "Chemical": ["Process Design", "Reaction Engineering", "Transport Phenomena", "Process Control",
                "Thermodynamics", "Fluid Mechanics", "Heat Transfer", "Plant Design",
                "Polymer Processing", "Biochemical Engineering", "Separation Processes"],

    "Maths & Computing": ["Numerical Methods", "Optimization Algorithms", "Statistical Modeling",
                         "Computational Mathematics", "Operations Research", "Linear Programming",
                         "Mathematical Simulation", "Computational Complexity"]
}

# Common technical skills across branches
common_technical_skills = [
    "Programming", "Problem Solving", "Technical Documentation", "Project Management",
    "Data Analysis", "Research", "Technical Presentation", "Critical Thinking",
    "System Analysis", "Technical Troubleshooting", "Analytical Skills"
]

# Professional skills and coding platforms - Enhanced with specifics
programming_skills = [
    # Original Programming Skills
    "Advanced Algorithm Design", "System Architecture Planning", "Code Optimization & Performance Tuning",
    "Debugging & Troubleshooting", "Agile & Scrum Methodologies", "CI/CD Pipeline Management",
    "Microservices Architecture", "Object-Oriented Design", "Functional Programming", "Test-Driven Development",
    "Cloud-Native Development", "Serverless Architecture", "Parallel Computing", "Distributed Systems",
    "RESTful API Design", "Database Schema Optimization", "Security-First Development", "Technical Documentation",
    "Cross-Platform Development", "Code Review & Mentorship", "Refactoring Legacy Systems", "UI/UX Implementation"
]

non_programming_skills = [
    # Business & Consulting
    "Consulting", "Business Analysis", "Strategic Planning", "Process Improvement",
    "Digital Transformation", "Business Development", "Market Research", "Sales",
    "Client Management", "Business Operations", "Revenue Management",

    # Data & Analytics
    "Data Analysis", "Data Science", "Data Analytics", "Microsoft Excel", "Tableau",
    "Data Visualization", "Financial Modeling", "Research", "Technical Analysis",
    "Microsoft Power BI", "Credit Risk Analysis",

    # Engineering Fields
    "Automobile Engineering", "Chemical Engineering", "Civil Engineering", "Mechanical Engineering",
    "Electrical Engineering", "Gas Pipeline Engineering", "Energy Technology", "Power Systems",
    "Petroleum Engineering", "Industrial Automation", "Electronics Design", "Circuit Analysis",
    "Metallurgy", "Product Development", "Computer-Aided Design",

    # IT & Security
    "Information Technology", "Cybersecurity", "Networking", "IT Infrastructure",
    "IT Systems", "Threat Analysis", "Risk Management", "Enterprise Architecture",

    # AI & Advanced Tech
    "Artificial Intelligence", "Machine Learning", "Internet of Things",

    # Finance
    "Banking", "Finance", "Risk Analysis", "Trading", "Financial Analysis",

    # Project & Product
    "Project Management", "Agile Methodologies", "Product Design", "Prototyping",
    "Innovation Management", "Design Thinking", "Process Engineering",

    # Education & Communication
    "Curriculum Design", "Teaching", "Subject Expertise", "Communication", "Coordination",

    # Marketing & Customer Relations
    "Digital Marketing", "SEO/SEM", "Territory Management", "Customer Service",

    # Other Specialized Skills
    "Automation Audit", "Safety", "Technical Problem Solving", "Troubleshooting",
    "System Integration", "Engineering Fundamentals", "Technical Proficiency", "Teamwork",
    "Software/Hardware Integration", "UX/UI Design"
]

coding_platforms = [
    {"name": "LeetCode", "ranks": ["Top 5%", "Knight", "Guardian", "1600+ rating"]},
    {"name": "HackerRank", "ranks": ["5-star", "Gold Medal", "Top 10%", "Certified"]},
    {"name": "CodeChef", "ranks": ["4-star", "5-star", "6-star", "Top 1000"]},
    {"name": "Codeforces", "ranks": ["Expert", "Candidate Master", "Master", "Grandmaster"]},
    {"name": "TopCoder", "ranks": ["Yellow", "Blue", "Purple", "Red"]},
    {"name": "AtCoder", "ranks": ["Green", "Blue", "Yellow", "Orange"]},
    {"name": "SPOJ", "ranks": ["100+ problems", "200+ problems", "500+ problems"]},
    {"name": "Google Kickstart", "ranks": ["Global Rank < 1000", "Regional Finalist", "Global Top 100"]}
]

# Work Experience Data - Enhanced with specifics
companies = [
    "Google", "Microsoft", "Amazon", "Meta", "Apple", "IBM", "Oracle", "Tesla", "Netflix", "Uber",
    "Adobe", "Salesforce", "Intel", "Cisco", "Twitter", "LinkedIn", "Airbnb", "Spotify", "PayPal", "Samsung",
    "Accenture", "Deloitte", "EY", "PwC", "KPMG", "McKinsey", "BCG", "Bain & Company", "Goldman Sachs", "JPMorgan Chase",
    "Morgan Stanley", "Tata Consultancy Services", "Infosys", "Wipro", "HCL Technologies", "Tech Mahindra",
    "Cognizant", "Capgemini", "Ericsson", "Huawei", "Dell", "HP", "Lenovo", "Qualcomm", "NVIDIA", "AMD", "Xiaomi",
    "Reliance Industries", "Larsen & Toubro", "Bharat Petroleum", "Indian Oil", "NTPC", "ONGC", "BHEL", "HAL",
    "Adani Group", "Tata Steel", "JSW Steel", "Hero MotoCorp", "Maruti Suzuki", "Bajaj Auto", "Mahindra & Mahindra",
    "ITC Limited", "Hindustan Unilever", "Asian Paints", "Dr. Reddy's", "Sun Pharma", "Cipla",
    "Zomato", "Swiggy", "Paytm", "Flipkart", "Ola", "BYJU'S", "Myntra", "MakeMyTrip", "Nykaa", "PolicyBazaar"
]

job_titles = {
    "CSE/IT": [
        "Software Engineer", "Senior Software Engineer", "Software Developer", "Full Stack Developer", "Frontend Developer",
        "Backend Developer", "Mobile App Developer", "DevOps Engineer", "Site Reliability Engineer", "Cloud Engineer",
        "Data Engineer", "Machine Learning Engineer", "AI Research Engineer", "QA Engineer", "Test Automation Engineer"
    ],
    "ECE/EE": [
        "Embedded Systems Engineer", "VLSI Design Engineer", "Hardware Engineer", "RF Engineer", "IoT Developer",
        "Firmware Engineer", "Electronics Design Engineer", "Telecommunications Engineer", "Control Systems Engineer",
        "Power Systems Engineer", "Electrical Design Engineer", "PCB Design Engineer", "Field Engineer", "Automation Engineer"
    ],
    "Mechanical/Automobile": [
        "Mechanical Design Engineer", "Product Development Engineer", "CAD Designer", "Automation Engineer",
        "Manufacturing Engineer", "R&D Engineer", "Quality Assurance Engineer", "Production Engineer",
        "Thermal Engineer", "Automotive Engineer", "Robotics Engineer", "Industrial Engineer", "Project Engineer"
    ],
    "Civil/Chemical": [
        "Design Engineer", "Project Engineer", "Structural Engineer", "Construction Manager", "Environmental Engineer",
        "Process Engineer", "Chemical Engineer", "Plant Engineer", "Quality Control Engineer", "Safety Engineer",
        "Pipeline Engineer", "Production Engineer", "Field Engineer", "Industrial Safety Engineer"
    ],
    "Data Science/Analytics": [
        "Data Scientist", "Data Analyst", "Business Intelligence Analyst", "Machine Learning Engineer",
        "AI Researcher", "Statistical Analyst", "Quantitative Analyst", "Research Scientist", "Analytics Manager"
    ],
    "Management/Consulting": [
        "Business Analyst", "Management Consultant", "Product Manager", "Project Manager", "Technical Program Manager",
        "Operations Manager", "Supply Chain Analyst", "Strategy Consultant", "Technology Consultant", "Digital Transformation Lead"
    ],
    "Finance/Banking": [
        "Financial Analyst", "Risk Analyst", "Investment Banking Analyst", "Credit Risk Analyst",
        "Quantitative Developer", "Financial Engineer", "Trading Systems Developer", "Compliance Analyst"
    ]
}

job_descriptions = [
    "Led a team of {team_size} engineers in developing a {product_type} that {improved_metric} by {percentage}%.",
    "Designed and implemented {feature_type} features resulting in {user_metric} increase of {percentage}%.",
    "Reduced {system_metric} by {percentage}% through optimization of {component_type}.",
    "Managed development of {project_type} with {budget_size} budget, delivering {time_metric} ahead of schedule.",
    "Created automated testing framework that improved code coverage from {before_percentage}% to {after_percentage}%.",
    "Architected scalable {architecture_type} handling {volume_metric} with {latency_metric} latency.",
    "Spearheaded migration to {technology_type}, reducing {cost_metric} by {percentage}% annually.",
    "Implemented {algorithm_type} algorithms that enhanced {performance_metric} by {factor}x.",
    "Collaborated with cross-functional teams to deliver {deliverable_type} that increased {business_metric} by {percentage}%.",
    "Mentored {junior_count} junior developers, improving team productivity by {percentage}%.",
    "Engineered {system_type} solution that reduced {problem_metric} by {percentage}% while improving {quality_metric}.",
    "Designed and developed {application_type} for {industry_type} sector, resulting in {business_outcome}.",
    "Conducted research on {research_area}, publishing findings that improved {industry_process} by {percentage}%.",
    "Optimized {engineering_component} design resulting in {cost_reduction} cost savings and {efficiency_gain}.",
    "Led the design and implementation of {infrastructure_type} supporting {capacity_metric} and {reliability_metric}.",
    "Developed innovative {technology_area} solution that achieved {industry_recognition} and {business_impact}.",
    "Implemented {automation_type} that reduced {manual_process} time from {before_time} to {after_time}.",
    "Drove {transformation_type} initiative resulting in {operational_improvement} and {financial_benefit}."
]

# Variables to fill in job descriptions
team_sizes = ["3-5", "5-7", "8-10", "10+", "12", "15", "20+"]
product_types = ["e-commerce platform", "fintech application", "healthcare system", "analytics dashboard", "machine learning pipeline", "mobile application", "enterprise solution", "IoT system", "automation framework", "security solution"]
feature_types = ["user-facing", "backend", "real-time", "analytics", "security", "performance", "integration", "AI/ML", "cross-platform", "cloud-native"]
improvement_metrics = ["customer satisfaction", "user retention", "conversion rate", "system performance", "revenue", "efficiency", "security compliance", "market reach", "product adoption"]
system_metrics = ["server load", "response time", "error rate", "infrastructure costs", "memory usage", "processing time", "operational expenses", "manual intervention", "system downtime"]
component_types = ["database queries", "API endpoints", "frontend rendering", "data processing pipelines", "authentication systems", "network protocols", "microservices", "cloud resources", "caching mechanisms"]
project_types = ["enterprise software", "consumer application", "internal tool", "data platform", "microservices architecture", "IoT system", "ML platform", "cloud migration", "digital transformation"]
budget_sizes = ["$500K", "$1M", "$2M+", "$250K", "$750K", "$100K", "$5M", "$3M", "$1.5M"]
time_metrics = ["2 months", "30%", "1 quarter", "6 weeks", "3 sprints", "45 days", "20% under budget", "ahead of competitors"]
architecture_types = ["microservices", "serverless architecture", "distributed systems", "cloud infrastructure", "real-time processing pipeline", "edge computing system", "hybrid cloud solution"]
volume_metrics = ["1M+ daily requests", "500TB of data", "10K concurrent users", "5B transactions annually", "100K events per second", "petabytes of storage", "millions of IoT devices"]
latency_metrics = ["sub-second", "<100ms", "50ms", "near real-time", "5ms", "<10ms", "millisecond-level"]
technology_types = ["cloud platform", "containerization", "modern tech stack", "automated CI/CD", "serverless computing", "edge computing", "distributed database", "AI/ML framework"]
cost_metrics = ["operational costs", "infrastructure expenses", "maintenance efforts", "development time", "deployment frequency", "cloud spending", "licensing costs", "support tickets"]
algorithm_types = ["machine learning", "optimization", "recommendation", "natural language processing", "computer vision", "predictive analytics", "anomaly detection", "reinforcement learning"]
performance_metrics = ["prediction accuracy", "search relevance", "query performance", "user engagement", "processing throughput", "conversion rate", "memory utilization", "battery efficiency"]
factors = ["2", "3", "4", "5", "10", "7", "8", "15", "20"]
deliverable_types = ["product features", "platform integrations", "reporting systems", "customer solutions", "internal tools", "analytics dashboards", "automation workflows", "security protocols"]
business_metrics = ["sales", "user acquisition", "customer lifetime value", "market share", "operational efficiency", "revenue growth", "customer satisfaction", "brand recognition", "ROI"]
junior_counts = ["3", "5", "7", "10+", "a team of", "several", "4", "6", "8", "12"]
system_types = ["distributed", "real-time", "fault-tolerant", "high-performance", "energy-efficient", "scalable", "cloud-native", "edge-computing"]
problem_metrics = ["maintenance downtime", "production defects", "customer complaints", "operating costs", "energy consumption", "carbon footprint", "safety incidents"]
quality_metrics = ["reliability", "performance", "user satisfaction", "production quality", "code maintainability", "system robustness", "security posture"]
application_types = ["enterprise solution", "mobile platform", "data analytics suite", "IoT framework", "engineering simulation", "process control system", "monitoring dashboard"]
industry_types = ["manufacturing", "healthcare", "finance", "retail", "energy", "transportation", "education", "telecommunications", "agriculture"]
business_outcomes = ["30% increase in operational efficiency", "25% reduction in costs", "$2M+ annual savings", "40% faster time-to-market", "95% customer satisfaction rating"]
research_areas = ["machine learning algorithms", "materials science", "process optimization", "energy efficiency", "structural analysis", "network security", "battery technology"]
industry_processes = ["manufacturing throughput", "design verification", "quality inspection", "energy conversion", "diagnostic accuracy", "threat detection", "production yield"]
engineering_components = ["mechanical assembly", "power distribution system", "cooling system", "structural support", "control circuit", "user interface", "signal processing algorithm"]
cost_reductions = ["$500K annual", "30%", "15% per unit", "$1.2M over project lifecycle", "45% on maintenance", "20% on materials"]
efficiency_gains = ["40% higher throughput", "25% energy savings", "doubled battery life", "30% smaller footprint", "75% less manual intervention"]
infrastructure_types = ["cloud platform", "manufacturing facility", "distributed network", "data center", "renewable energy system", "smart building solution", "industrial automation system"]
capacity_metrics = ["millions of daily users", "petabytes of data", "gigawatt-scale energy", "nationwide distribution", "enterprise-wide deployment", "multi-site operations"]
reliability_metrics = ["99.99% uptime", "zero unplanned downtime", "mean-time-between-failures of 5+ years", "fault-tolerant operation", "disaster recovery within minutes"]
technology_areas = ["AI-driven optimization", "IoT sensing network", "renewable energy integration", "predictive maintenance", "autonomous systems", "real-time analytics", "immersive user experience"]
industry_recognitions = ["patent award", "industry certification", "technical publication", "conference presentation", "innovation award", "successful regulatory approval"]
business_impacts = ["$3M+ revenue increase", "40% market share growth", "35% customer acquisition boost", "50% reduction in customer churn", "significant competitive advantage"]
automation_types = ["CI/CD pipeline", "test automation framework", "production workflow", "data processing system", "procurement process", "quality inspection", "regulatory compliance reporting"]
manual_processes = ["deployment", "testing", "data entry", "quality inspection", "code review", "reporting", "maintenance scheduling", "document processing"]
before_times = ["days", "weeks", "hours", "months", "multiple engineer-days", "quarterly cycles", "manual weeklong process"]
after_times = ["minutes", "hours", "days", "automated daily process", "seconds", "real-time", "continuous process"]
transformation_types = ["digital", "agile", "DevOps", "lean manufacturing", "Industry 4.0", "cloud migration", "AI-driven", "sustainability"]
operational_improvements = ["50% faster time-to-market", "35% increase in production capacity", "25% reduction in operational overhead", "near-zero manual intervention", "24/7 automated operation"]
financial_benefits = ["$2M+ annual savings", "15% margin improvement", "30% OPEX reduction", "40% better ROI", "significant working capital optimization", "25% higher resource utilization"]

# Extra-curricular and hobbies - Expanded
extracurricular = [
    "Led volunteer team at local NGO, coordinating 15+ members and 5 community events annually",
    "Elected President of college programming club with 200+ members",
    "Organized campus hackathon with 300+ participants from 20+ colleges",
    "Founded and managed technical blog reaching 5,000+ monthly readers",
    "Represented university in national coding competition, securing top 5% ranking",
    "Conducted 10+ technical workshops teaching programming to 500+ students",
    "Member of college debate team, winning 3 inter-university competitions",
    "Coordinated college technical festival with budget of â‚¹500,000 and 5,000+ attendees",
    "Developed open-source library with 100+ GitHub stars and 20+ contributors",
    "Participated in Model United Nations conferences, receiving Best Delegate award twice",
    "Volunteered 200+ hours teaching computer literacy to underprivileged children",
    "Published 5 technical articles in renowned programming magazines",
    "Captain of college cricket team that won inter-university tournament",
    "Led college robotics team to national competition finals, ranking 3rd place",
    "Founded college entrepreneurship cell, mentoring 10+ student startups",
    "Managed college cultural committee organizing events for 2,000+ students",
    "Volunteered for flood relief operations, helping 500+ affected families",
    "Served as Campus Ambassador for leading tech company, conducting 8 workshops",
    "Organized blood donation camp collecting 250+ units in a single day",
    "Delivered TedX talk on technology ethics viewed by 10,000+ people",
    "Mentored 15 juniors in technical skills who secured placements in top companies",
    "Developed and maintained department website with 500+ daily visitors",
    "Represented college in national quiz competition, securing 2nd position",
    "Led environmental conservation drive, planting 1,000+ trees on campus"
]

hobbies = [
    "Reading technical blogs and books on emerging technologies",
    "Competitive programming with 300+ solved problems",
    "Contributing to open-source projects with 50+ pull requests",
    "Photography with portfolio of 1,000+ curated images",
    "Hiking, having covered 20+ trails across the country",
    "Chess with 1800+ ELO rating on chess.com",
    "Learning foreign languages (proficient in 3+ languages)",
    "Music production with self-published album reaching 10,000+ streams",
    "3D modeling and printing functional prototypes",
    "Podcasting on technology trends with 2,000+ monthly listeners",
    "Robotics, having built 5+ functional robots",
    "Game development, with 2 indie games published on Steam",
    "Participating in marathon runs, completed 5 full marathons",
    "Digital art creation with 1,500+ followers on Instagram",
    "Amateur astronomy with published photographs of deep sky objects",
    "Cooking international cuisines, mastered 30+ authentic recipes",
    "Playing classical music instruments with 10+ years of training",
    "Participating in national-level debate competitions",
    "Wildlife photography with published work in nature magazines",
    "Amateur radio operator with international contacts across 20+ countries",
    "Drone piloting and aerial photography of architectural landmarks",
    "Cryptocurrency trading and blockchain technology research",
    "DIY electronics, having built custom smart home solutions",
    "Participating in hackathons, winning 3 major competitions"
]

# Enhanced generation functions

def get_branch_from_degree(degree):
    """Determine engineering branch from degree"""
    for branch, degrees in engineering_branches.items():
        if any(degree_name in degree for degree_name in degrees) or branch.lower() in degree.lower():
            return branch
    return None

def get_random_branch():
    """Get a random engineering branch"""
    return random.choice(list(engineering_branches.keys()))

def get_courses_for_branch(branch, count=4):
    """Get relevant courses for a specific branch"""
    branch_courses = []

    # Add branch-specific courses if available
    if branch in courses_by_branch:
        branch_courses.extend(random.sample(courses_by_branch[branch], min(count-1, len(courses_by_branch[branch]))))

    # Add some math courses
    branch_courses.append(random.choice(math_courses))

    # Add some common courses
    branch_courses.extend(random.sample(common_courses, min(2, len(common_courses))))

    # If we still need more courses, add from other related branches
    if len(branch_courses) < count:
        related_branches = []
        if branch in ["CSE", "IT"]:
            related_branches = ["Maths & Computing"]
        elif branch in ["ECE", "EE"]:
            related_branches = ["Maths & Computing", "Mechanical"]
        elif branch == "Mechanical":
            related_branches = ["Civil", "Automobile"]
        elif branch == "Civil":
            related_branches = ["Mechanical"]
        elif branch == "Chemical":
            related_branches = ["Mechanical", "Petroleum"]

        for related_branch in related_branches:
            if related_branch in courses_by_branch and len(branch_courses) < count:
                branch_courses.append(random.choice(courses_by_branch[related_branch]))

    # Shuffle and trim to exactly the count requested
    random.shuffle(branch_courses)
    return branch_courses[:count]

def generate_github_link(name):
    """Generate a realistic GitHub profile link based on name"""
    lowercase_name = name.lower().replace(" ", "")
    github_username = random.choice([
        lowercase_name,
        f"{lowercase_name}{random.randint(1, 99)}",
        f"{name.split()[0].lower()}-{name.split()[1].lower()}",
        f"{name.split()[0][0].lower()}{name.split()[1].lower()}",
        f"{random.choice(github_prefixes)}{name.split()[0].lower()}",
    ])
    return f"github.com/{github_username}"

def generate_linkedin_link(name):
    """Generate a realistic LinkedIn profile link based on name"""
    lowercase_name = name.lower().replace(" ", "")
    return f"linkedin.com/in/{lowercase_name}{random.choice(['', '-' + random.choice(['dev', 'eng', 'tech', 'pro'])])}"

def generate_projects_for_branch(branch, num_projects=None):
    """Generate projects relevant to a specific engineering branch"""
    if num_projects is None:
        # Probability distribution for number of projects
        num_projects = random.choices([1, 2, 3, 4], weights=[0.2, 0.4, 0.3, 0.1])[0]

    projects = []

    # Map branches to relevant project domains
    branch_domain_mapping = {
        "CSE": ["Software Development", "Web Development", "Mobile Development", "AI & Machine Learning", "Cloud & DevOps", "Cybersecurity"],
        "IT": ["Web Development", "Cloud & DevOps", "Data Science & Analytics", "Cybersecurity", "Business & Consulting"],
        "ECE": ["IoT & Embedded Systems", "AI & Machine Learning", "Mobile Development", "Electrical & Energy Systems"],
        "EE": ["Electrical & Energy Systems", "IoT & Embedded Systems", "Cloud & DevOps"],
        "Mechanical": ["Mechanical & Automotive", "IoT & Embedded Systems"],
        "Civil": ["Civil & Construction", "Business & Consulting"],
        "Chemical": ["Chemical & Process Engineering", "Data Science & Analytics"],
        "Automobile": ["Mechanical & Automotive", "IoT & Embedded Systems"],
        "Petroleum": ["Chemical & Process Engineering"],
        "Maths & Computing": ["Data Science & Analytics", "AI & Machine Learning", "Finance & Risk Management"]
    }

    # Default domains if branch isn't in mapping
    default_domains = ["Software Development", "Data Science & Analytics", "Business & Consulting"]

    # Get relevant domains for the branch
    relevant_domains = branch_domain_mapping.get(branch, default_domains)

    # Add one interdisciplinary domain occasionally
    if random.random() < 0.3:
        other_domains = [d for d in project_domains.keys() if d not in relevant_domains]
        if other_domains:
            relevant_domains.append(random.choice(other_domains))

    # Generate projects
    used_titles = []
    for _ in range(num_projects):
        # Select a domain for this project
        domain = random.choice(relevant_domains)

        # Get available titles for this domain
        available_titles = [t for t in project_domains[domain]["titles"] if t not in used_titles]
        if not available_titles:
            # If no titles available in preferred domain, try another domain
            other_domains = [d for d in relevant_domains if d != domain]
            if not other_domains:
                break
            domain = random.choice(other_domains)
            available_titles = [t for t in project_domains[domain]["titles"] if t not in used_titles]
            if not available_titles:
                break

        title = random.choice(available_titles)
        used_titles.append(title)

        # Rest of the function remains the same
        # ...

        # Select technologies relevant to this domain and branch
        primary_tools = []

        # Different technology selection based on branch and domain
        if branch in ["CSE", "IT", "Maths & Computing"]:
            if "Web" in domain:
                primary_tools.extend(random.sample(tools_tech["Web Frontend"] + tools_tech["Web Backend"], 2))
            elif "Mobile" in domain:
                primary_tools.extend(random.sample(tools_tech["Mobile"], 1) + random.sample(tools_tech["Languages"], 1))
            elif "Data" in domain or "Machine Learning" in domain or "Analytics" in domain:
                primary_tools.extend(random.sample(tools_tech["Data Science"], 2))
            elif "DevOps" in domain or "Cloud" in domain:
                primary_tools.extend(random.sample(tools_tech["DevOps"], 2))
            elif "Blockchain" in domain:
                primary_tools.extend(random.sample(tools_tech["Blockchain"], 2))
            else:
                primary_tools.extend(random.sample(tools_tech["Languages"], 1) + random.sample(tools_tech["Database"], 1))
        elif branch in ["ECE", "EE"]:
            if "IoT" in domain or "Embedded" in domain:
                primary_tools.extend(random.sample(tools_tech["Electrical & IoT"], 2))
            elif "AI" in domain or "Machine Learning" in domain:
                primary_tools.extend(random.sample(tools_tech["Data Science"], 1) + random.sample(tools_tech["Languages"], 1))
            else:
                primary_tools.extend(random.sample(tools_tech["Electrical & IoT"], 1) + random.sample(tools_tech["Languages"], 1))
        elif branch in ["Mechanical", "Civil", "Automobile"]:
            if "CAD" in domain or "Automotive" in domain:
                primary_tools.extend(random.sample(tools_tech["CAD & Engineering"], 2))
            elif "IoT" in domain:
                primary_tools.extend(random.sample(tools_tech["Electrical & IoT"], 1) + random.sample(tools_tech["Languages"], 1))
            else:
                primary_tools.extend(random.sample(tools_tech["CAD & Engineering"], 1) + random.sample(tools_tech["Languages"], 1))
        elif branch in ["Chemical", "Petroleum"]:
            if "Process" in domain:
                primary_tools.extend(random.sample(tools_tech["Chemical & Process"], 2))
            elif "Data" in domain:
                primary_tools.extend(random.sample(tools_tech["Data Science"], 1) + random.sample(tools_tech["Languages"], 1))
            else:
                primary_tools.extend(random.sample(tools_tech["Chemical & Process"], 1) + random.sample(tools_tech["Languages"], 1))

        # Add some keywords from the domain
        domain_keywords = random.sample(project_domains[domain]["keywords"], min(3, len(project_domains[domain]["keywords"])))

        # Make sure we have at least 2 technologies
        if len(primary_tools) < 2:
            primary_tools.extend(random.sample(tools_tech["Languages"], 2 - len(primary_tools)))

        # Remove duplicates
        primary_tools = list(dict.fromkeys(primary_tools))

        impact_metric = random.choice(project_impact_metrics)
        impact_area = random.choice(project_impacts)

        description = random.choice(project_descriptions)

        accomplishments = []
        num_accomplishments = random.randint(1, 3)
        for _ in range(num_accomplishments):
            metrics = [
                f"Reduced load time by {random.randint(20, 60)}%",
                f"Increased test coverage to {random.randint(85, 98)}%",
                f"Processed {random.randint(10, 500)}K+ data points daily",
                f"Achieved {random.randint(95, 99)}.{random.randint(1, 9)}% uptime",
                f"Supported {random.randint(100, 10000)}+ concurrent users",
                f"Decreased memory usage by {random.randint(20, 50)}%",
                f"Improved algorithm efficiency by {random.randint(2, 10)}x",
                f"Cut development time by {random.randint(20, 50)}%"
            ]

            # Add some domain-specific accomplishments
            if "Web" in domain:
                domain_metrics = [
                    f"Improved SEO ranking by {random.randint(15, 50)} positions",
                    f"Reduced bounce rate by {random.randint(15, 40)}%",
                    f"Enhanced mobile responsiveness across {random.randint(10, 50)}+ device types"
                ]
                metrics.extend(domain_metrics)
            elif "Data" in domain or "Analytics" in domain:
                domain_metrics = [
                    f"Improved prediction accuracy by {random.randint(10, 30)} percentage points",
                    f"Reduced false positives by {random.randint(30, 70)}%",
                    f"Automated data cleaning for {random.randint(10, 50)}+ data sources"
                ]
                metrics.extend(domain_metrics)
            elif "Mobile" in domain:
                domain_metrics = [
                    f"Reduced app size by {random.randint(20, 50)}%",
                    f"Improved battery efficiency by {random.randint(15, 40)}%",
                    f"Implemented offline functionality with {random.randint(90, 99)}% feature parity"
                ]
                metrics.extend(domain_metrics)

            accomplishments.append(random.choice(metrics))

        team_info = ""
        if random.random() < 0.7:  # 70% chance of team project
            team_size = random.randint(2, 8)
            team_info = f" in a team of {team_size}"

        duration_months = random.randint(1, 8)
        duration = f"{duration_months} month{'s' if duration_months > 1 else ''}"

        # Add domain keywords to the tools list
        tools_list = primary_tools + [k for k in domain_keywords if k not in primary_tools]
        tools_list = tools_list[:4]  # Limit to 4 tools

        project_info = {
            "Title": title,
            "Category": domain,
            "Description": description,
            "Impact": f"{impact_area} {impact_metric}",
            "Tools": ", ".join(tools_list),
            "Duration": duration,
            "Team Size": team_info,
            "Accomplishments": accomplishments
        }

        projects.append(project_info)

    return projects

def generate_technical_skills(branch, has_projects=False, project_tools=None):
    """Generate technical skills relevant to a specific branch"""
    # Select programming languages based on branch
    if branch in ["CSE", "IT", "Maths & Computing"]:
        languages = random.sample(["Python", "Java", "C++", "JavaScript", "TypeScript", "C#", "Go"], random.randint(3, 5))
    elif branch in ["ECE", "EE"]:
        languages = random.sample(["C", "C++", "Python", "MATLAB", "Embedded C", "Verilog", "VHDL"], random.randint(3, 4))
    elif branch in ["Mechanical", "Civil", "Automobile"]:
        languages = random.sample(["MATLAB", "Python", "C++", "C", "R"], random.randint(2, 3))
    elif branch in ["Chemical", "Petroleum"]:
        languages = random.sample(["MATLAB", "Python", "R", "C++"], random.randint(2, 3))
    else:
        languages = random.sample(tools_tech["Languages"], random.randint(2, 4))

    # Extract frameworks and tools from projects if available
    frameworks = []
    if has_projects and project_tools:
        for tools in project_tools:
            tool_list = [t.strip() for t in tools.split(",")]
            frameworks.extend([t for t in tool_list if t not in languages and t not in frameworks])

        # Limit the number of frameworks
        frameworks = frameworks[:6]
    else:
        # Select frameworks based on branch
        if branch in ["CSE", "IT"]:
            framework_categories = ["Web Frontend", "Web Backend", "Database", "DevOps"]
            for category in random.sample(framework_categories, min(3, len(framework_categories))):
                frameworks.extend(random.sample(tools_tech[category], random.randint(1, 2)))
        elif branch in ["ECE", "EE"]:
            frameworks.extend(random.sample(tools_tech["Electrical & IoT"], random.randint(2, 3)))
        elif branch in ["Mechanical", "Civil", "Automobile"]:
            frameworks.extend(random.sample(tools_tech["CAD & Engineering"], random.randint(2, 3)))
        elif branch in ["Chemical", "Petroleum"]:
            frameworks.extend(random.sample(tools_tech["Chemical & Process"], random.randint(2, 3)))
        elif branch == "Maths & Computing":
            frameworks.extend(random.sample(tools_tech["Data Science"], random.randint(2, 3)))
            frameworks.extend(random.sample(tools_tech["Database"], random.randint(1, 2)))

        frameworks = list(dict.fromkeys(frameworks))  # Remove duplicates

    # Select professional skills based on branch
    if branch in branch_specific_skills:
        prof_skills = random.sample(branch_specific_skills[branch], min(3, len(branch_specific_skills[branch])))
    else:
        prof_skills = random.sample(programming_skills, random.randint(3, 5))

    # Add some common skills
    prof_skills.extend(random.sample(common_technical_skills, min(2, len(common_technical_skills))))
    prof_skills = list(dict.fromkeys(prof_skills))[:5]  # Remove duplicates and limit to 5

    # Determine if student has competitive programming experience
    # Higher probability for CSE/IT students
    competitive_prob = 0.8 if branch in ["CSE", "IT", "Maths & Computing"] else 0.3
    has_competitive = random.random() < competitive_prob

    if has_competitive:
        platform = random.choice(coding_platforms)
        problems_solved = random.randint(50, 500)

        competitive_info = {
            "Platform": platform["name"],
            "Rank": random.choice(platform["ranks"]),
            "Problems Solved": problems_solved,
            "Achievements": []
        }

        if random.random() < 0.7:
            achievements = [
                f"Ranked in top {random.randint(1, 20)}% globally",
                f"Solved {random.randint(5, 30)}+ hard problems",
                f"Participated in {random.randint(2, 10)} competitive programming contests",
                f"Maintained {random.randint(85, 99)}% solution acceptance rate"
            ]
            competitive_info["Achievements"] = random.sample(achievements, random.randint(1, 2))
    else:
        competitive_info = None

    # Select databases based on branch
    if branch in ["CSE", "IT", "Maths & Computing"]:
        databases = random.sample(tools_tech["Database"], random.randint(2, 3))
    else:
        databases = random.sample(tools_tech["Database"], random.randint(1, 2))

    # Decide on certifications based on branch and random chance
    certifications = []
    cert_prob = 0.4 if branch in ["CSE", "IT", "ECE", "EE"] else 0.2
    if random.random() < cert_prob:
        cert_options_by_branch = {
            "CSE": [
                "AWS Certified Developer",
                "Microsoft Certified: Azure Developer Associate",
                "Google Cloud Professional Developer",
                "Oracle Certified Professional, Java SE Developer",
                "TensorFlow Developer Certificate"
            ],
            "IT": [
                "AWS Certified Solutions Architect",
                "CompTIA Security+",
                "Certified Kubernetes Administrator (CKA)",
                "Certified Information Systems Security Professional (CISSP)",
                "Microsoft 365 Certified: Enterprise Administrator Expert"
            ],
            "ECE": [
                "Cisco Certified Network Associate (CCNA)",
                "CompTIA A+",
                "Certified IoT Practitioner",
                "FPGA Design Certification",
                "Embedded Systems Certification"
            ],
            "EE": [
                "Certified Energy Manager",
                "Professional Engineer (PE)",
                "Power Systems Engineer Certification",
                "Automation Professional Certification",
                "Renewable Energy Professional"
            ],
            "Mechanical": [
                "SolidWorks Professional Certification",
                "AutoCAD Certified Professional",
                "Certified Quality Engineer",
                "Six Sigma Green Belt",
                "Project Management Professional (PMP)"
            ],
            "Civil": [
                "AutoCAD Civil 3D Certified Professional",
                "Professional Engineer (PE)",
                "LEED Green Associate",
                "Project Management Professional (PMP)",
                "Structural Engineering Certification"
            ],
            "Chemical": [
                "Certified Process Safety Professional",
                "Project Management Professional (PMP)",
                "Six Sigma Green Belt",
                "Certified Energy Manager",
                "Environmental Management Certification"
            ]
        }

        branch_certs = cert_options_by_branch.get(branch, ["Professional Certification", "Technical Certification"])
        num_certs = random.randint(1, 2)
        certifications = random.sample(branch_certs, min(num_certs, len(branch_certs)))

    skills = {
        "Programming Languages": languages,
        "Frameworks & Libraries": frameworks,
        "Databases": databases,
        "Professional Skills": prof_skills,
        "Competitive Programming": competitive_info,
        "Certifications": certifications if certifications else None
    }

    return skills

def generate_work_experience(branch, college_year):
    """Generate 0-3 detailed work experiences relevant to branch and graduation year"""
    # Calculate probability of having work experience based on graduation year
    # Recent graduates are less likely to have experience
    current_year = 2025
    years_since_graduation = current_year - int(college_year.split("-")[1])

    # Higher probability of experience for older graduates
    if years_since_graduation <= 0:  # Still in college
        exp_probability = 0.2  # 20% chance of internship experience
        max_experiences = 2
    elif years_since_graduation == 1:
        exp_probability = 0.6
        max_experiences = 2
    elif years_since_graduation == 2:
        exp_probability = 0.8
        max_experiences = 2
    else:
        exp_probability = 0.9
        max_experiences = 3

    if random.random() > exp_probability:
        return []  # No experience

    num_experiences = random.randint(1, max_experiences)

    experiences = []
    used_companies = []

    # Select relevant job categories based on branch
    if branch in ["CSE", "IT"]:
        job_categories = ["CSE/IT", "Data Science/Analytics"]
    elif branch in ["ECE", "EE"]:
        job_categories = ["ECE/EE", "CSE/IT"]
    elif branch in ["Mechanical", "Automobile"]:
        job_categories = ["Mechanical/Automobile", "Management/Consulting"]
    elif branch in ["Civil", "Chemical", "Petroleum"]:
        job_categories = ["Civil/Chemical", "Management/Consulting"]
    else:
        job_categories = list(job_titles.keys())

    # Add data science as an option for Maths & Computing
    if branch == "Maths & Computing":
        job_categories = ["Data Science/Analytics", "CSE/IT", "Finance/Banking"]

    for i in range(num_experiences):
        available_companies = [c for c in companies if c not in used_companies]
        if not available_companies:
            break

        company = random.choice(available_companies)
        used_companies.append(company)

        # Select job category and title
        job_category = random.choice(job_categories)
        job_title = random.choice(job_titles[job_category])

        # Determine job duration based on graduation and experience
        current_year = 2025

        # For students still in college, only internships
        if years_since_graduation <= 0:
            is_internship = True
            months = random.randint(2, 6)
            start_year = random.randint(current_year - 3, current_year - 1)
            if random.random() < 0.8:  # Most likely completed
                end_year = start_year
                duration = f"{start_year} ({months} months)"
            else:  # Some still ongoing
                end_year = "Present"
                duration = f"{start_year} - {end_year} ({months} months)"

            # Adjust title for internships
            if "intern" not in job_title.lower():
                job_title = job_title.split(" ")[0] + " Intern"
        else:
            is_internship = False
            if i == 0:  # Most recent job
                if random.random() < 0.7:  # 70% chance current job is ongoing
                    end_year = "Present"
                    start_year = current_year - random.randint(1, min(3, years_since_graduation))
                else:
                    start_year = current_year - random.randint(1, min(3, years_since_graduation))
                    end_year = current_year
            else:
                max_start = current_year - 1
                for prev_exp in experiences:
                    prev_duration = prev_exp["Duration"]
                    if "Present" in prev_duration:
                        continue
                    prev_years = [int(y) for y in prev_duration.split(" - ") if y.isdigit()]
                    if prev_years and prev_years[0] < max_start:
                        max_start = prev_years[0]

                start_year = max_start - random.randint(1, 3)
                end_year = max_start

            duration = f"{start_year} - {end_year}"

        # Generate job responsibilities
        num_responsibilities = random.randint(2, 4)
        responsibilities = []
        for _ in range(num_responsibilities):
            desc_template = random.choice(job_descriptions)

            # Fill in template with random values
            filled_desc = desc_template.format(
                team_size=random.choice(team_sizes),
                product_type=random.choice(product_types),
                improved_metric=random.choice(improvement_metrics),
                percentage=random.randint(15, 85),
                feature_type=random.choice(feature_types),
                user_metric=random.choice(improvement_metrics),
                system_metric=random.choice(system_metrics),
                component_type=random.choice(component_types),
                project_type=random.choice(project_types),
                budget_size=random.choice(budget_sizes),
                time_metric=random.choice(time_metrics),
                before_percentage=random.randint(40, 70),
                after_percentage=random.randint(75, 95),
                architecture_type=random.choice(architecture_types),
                volume_metric=random.choice(volume_metrics),
                latency_metric=random.choice(latency_metrics),
                technology_type=random.choice(technology_types),
                cost_metric=random.choice(cost_metrics),
                algorithm_type=random.choice(algorithm_types),
                performance_metric=random.choice(performance_metrics),
                factor=random.choice(factors),
                deliverable_type=random.choice(deliverable_types),
                business_metric=random.choice(business_metrics),
                junior_count=random.choice(junior_counts),
                system_type=random.choice(system_types),
                problem_metric=random.choice(problem_metrics),
                quality_metric=random.choice(quality_metrics),
                application_type=random.choice(application_types),
                industry_type=random.choice(industry_types),
                business_outcome=random.choice(business_outcomes),
                research_area=random.choice(research_areas),
                industry_process=random.choice(industry_processes),
                engineering_component=random.choice(engineering_components),
                cost_reduction=random.choice(cost_reductions),
                efficiency_gain=random.choice(efficiency_gains),
                infrastructure_type=random.choice(infrastructure_types),
                capacity_metric=random.choice(capacity_metrics),
                reliability_metric=random.choice(reliability_metrics),
                technology_area=random.choice(technology_areas),
                industry_recognition=random.choice(industry_recognitions),
                business_impact=random.choice(business_impacts),
                automation_type=random.choice(automation_types),
                manual_process=random.choice(manual_processes),
                before_time=random.choice(before_times),
                after_time=random.choice(after_times),
                transformation_type=random.choice(transformation_types),
                operational_improvement=random.choice(operational_improvements),
                financial_benefit=random.choice(financial_benefits)
            )

            responsibilities.append(filled_desc)

        # Technologies used based on job category and branch
        tech_used = []

        if job_category == "CSE/IT":
            tech_categories = ["Languages", "Web Frontend", "Web Backend", "Database", "DevOps"]
        elif job_category == "ECE/EE":
            tech_categories = ["Languages", "Electrical & IoT", "CAD & Engineering"]
        elif job_category == "Mechanical/Automobile":
            tech_categories = ["CAD & Engineering", "Languages"]
        elif job_category == "Civil/Chemical":
            tech_categories = ["CAD & Engineering", "Chemical & Process", "Languages"]
        elif job_category == "Data Science/Analytics":
            tech_categories = ["Languages", "Data Science", "Database"]
        elif job_category == "Management/Consulting":
            tech_categories = ["Languages", "Database"]
        elif job_category == "Finance/Banking":
            tech_categories = ["Languages", "Database", "Data Science"]
        else:
            tech_categories = random.sample(list(tools_tech.keys()), random.randint(2, 3))

        for category in tech_categories:
            if category in tools_tech:
                tech_used.extend(random.sample(tools_tech[category], random.randint(1, 2)))

        tech_used = list(dict.fromkeys(tech_used))
        if len(tech_used) > 6:
            tech_used = tech_used[:6]

        exp = {
            "Company": company,
            "Job Title": job_title,
            "Duration": duration,
            "Responsibilities": responsibilities,
            "Technologies": tech_used
        }

        experiences.append(exp)

    return experiences

def generate_non_programming_skills(branch):
    """Generate relevant non-programming skills based on branch"""

    # Define categories of non-programming skills relevant to different branches
    branch_relevant_categories = {
        "CSE": ["Business & Consulting", "Data & Analytics", "Soft Skills", "Project Management"],
        "IT": ["Business & Consulting", "Data & Analytics", "Soft Skills", "Project Management", "IT & Security"],
        "ECE": ["Soft Skills", "Project Management", "Engineering Fields", "IT & Security"],
        "EE": ["Soft Skills", "Project Management", "Engineering Fields", "Energy & Power"],
        "Mechanical": ["Soft Skills", "Project Management", "Engineering Fields", "Product Development"],
        "Civil": ["Soft Skills", "Project Management", "Engineering Fields", "Construction & Planning"],
        "Chemical": ["Soft Skills", "Project Management", "Engineering Fields", "Process & Safety"],
        "Automobile": ["Soft Skills", "Project Management", "Engineering Fields", "Product Development"],
        "Petroleum": ["Soft Skills", "Project Management", "Engineering Fields", "Energy & Resources"],
        "Maths & Computing": ["Business & Consulting", "Data & Analytics", "Soft Skills", "Project Management", "Finance"]
    }

    # Categories for each broad skill area
    skill_categories = {
        "Business & Consulting": [
            "Consulting", "Business Analysis", "Strategic Planning", "Process Improvement",
            "Digital Transformation", "Business Development", "Market Research", "Sales",
            "Client Management", "Business Operations", "Revenue Management"
        ],
        "Data & Analytics": [
            "Data Analysis", "Data Science", "Data Analytics", "Microsoft Excel", "Tableau",
            "Data Visualization", "Financial Modeling", "Research", "Technical Analysis",
            "Microsoft Power BI", "Credit Risk Analysis"
        ],
        "Soft Skills": [
            "Communication", "Teamwork", "Leadership", "Time Management", "Problem Solving",
            "Critical Thinking", "Creativity", "Adaptability", "Organization", "Planning",
            "Conflict Resolution", "Self-Motivation", "Emotional Intelligence", "Networking"
        ],
        "Project Management": [
            "Project Management", "Agile Methodologies", "Scrum", "Risk Management",
            "Process Improvement", "Documentation", "Requirements Gathering", "Stakeholder Management"
        ],
        "IT & Security": [
            "Information Technology", "Cybersecurity", "Networking", "IT Infrastructure",
            "IT Systems", "Threat Analysis", "Risk Management", "Enterprise Architecture"
        ],
        "Engineering Fields": [
            "Technical Problem Solving", "Troubleshooting", "System Integration",
            "Engineering Fundamentals", "Technical Proficiency", "Quality Control",
            "Engineering Design", "Technical Documentation", "Laboratory Techniques"
        ],
        "Energy & Power": [
            "Energy Technology", "Power Systems", "Renewable Energy", "Energy Efficiency",
            "Smart Grid", "Energy Management", "Power Distribution", "Utility Operations"
        ],
        "Product Development": [
            "Product Design", "Prototyping", "Design Thinking", "User Research",
            "Quality Assurance", "Manufacturing Processes", "Industrial Design",
            "Product Lifecycle Management", "Design for Manufacturing"
        ],
        "Construction & Planning": [
            "Construction Management", "Site Planning", "Building Codes", "Cost Estimation",
            "Sustainable Design", "Urban Planning", "Infrastructure Development",
            "Construction Safety", "Construction Scheduling"
        ],
        "Process & Safety": [
            "Process Safety", "Risk Assessment", "Quality Control", "Process Optimization",
            "Environmental Compliance", "Laboratory Techniques", "Hazard Analysis",
            "Regulatory Compliance", "Safety Management"
        ],
        "Energy & Resources": [
            "Resource Management", "Extraction Techniques", "Energy Production",
            "Environmental Impact Assessment", "Reservoir Analysis", "Field Operations",
            "Drilling Operations", "Production Optimization"
        ],
        "Finance": [
            "Financial Analysis", "Risk Assessment", "Banking", "Investment Analysis",
            "Portfolio Management", "Trading", "Financial Modeling", "Credit Analysis",
            "Corporate Finance", "Financial Planning"
        ],
        "Industry Knowledge": [
            "Banking", "Finance", "Healthcare", "E-commerce", "Telecommunications",
            "Manufacturing", "Retail", "Insurance", "Education", "Government"
        ]
    }

    # Get relevant categories for the branch
    default_categories = ["Soft Skills", "Project Management"]
    relevant_categories = branch_relevant_categories.get(branch, default_categories)

    # Select 2-3 categories
    selected_categories = random.sample(relevant_categories, min(random.randint(2, 3), len(relevant_categories)))

    # Add Industry Knowledge as an occasional category
    if random.random() < 0.3:
        selected_categories.append("Industry Knowledge")

    # Select skills from each category
    selected_skills = {}
    for category in selected_categories:
        if category in skill_categories:
            num_skills = random.randint(2, 4)
            category_skills = skill_categories[category]
            selected_skills[category] = random.sample(category_skills, min(num_skills, len(category_skills)))

    # Add certifications based on branch (30% chance)
    has_certifications = random.random() < 0.3
    certifications = []

    if has_certifications:
        cert_options_by_branch = {
            "CSE": [
                "Project Management Professional (PMP)",
                "Certified Business Analysis Professional (CBAP)",
                "Certified ScrumMaster (CSM)",
                "Six Sigma Green Belt"
            ],
            "IT": [
                "ITIL Foundation",
                "Certified Information Systems Auditor (CISA)",
                "Project Management Professional (PMP)",
                "Six Sigma Green Belt"
            ],
            "ECE": [
                "Project Management Professional (PMP)",
                "Six Sigma Green Belt",
                "Certified Electronics Technician"
            ],
            "EE": [
                "Energy Management Certification",
                "Project Management Professional (PMP)",
                "Six Sigma Green Belt"
            ],
            "Mechanical": [
                "Six Sigma Green Belt",
                "Project Management Professional (PMP)",
                "Certified Quality Engineer"
            ],
            "Civil": [
                "Project Management Professional (PMP)",
                "LEED Accredited Professional",
                "Construction Management Certification"
            ],
            "Chemical": [
                "Six Sigma Green Belt",
                "Process Safety Management Certification",
                "Certified Safety Professional"
            ]
        }

        branch_certs = cert_options_by_branch.get(branch, ["Professional Certification"])
        num_certs = random.randint(1, 2)
        certifications = random.sample(branch_certs, min(num_certs, len(branch_certs)))

    skills = {
        "Categories": selected_skills,
        "Certifications": certifications if certifications else None
    }

    return skills

def generate_objective(branch, has_experience, degree_type):
    """Generate career objective based on branch, experience level and skills"""
    student_objectives = [
        "Seeking an entry-level {position} position to apply my {skills} skills in a collaborative environment.",
        "Recent {degree} graduate with strong {skills} expertise looking for opportunities to contribute to innovative projects.",
        "Aspiring {position} with {academic} background eager to leverage technical knowledge in solving real-world challenges.",
        "Motivated {degree} student with {projects} projects experience seeking internship opportunities in {field}.",
        "Detail-oriented {degree} graduate with expertise in {skills}, looking to begin my career with an innovative organization."
    ]

    professional_objectives = [
        "Experienced {position} with {years}+ years of expertise in {skills}, seeking challenging opportunities to drive innovation.",
        "{position} with proven track record in delivering {solutions} solutions, aiming to leverage my expertise in {field}.",
        "Results-driven {position} with expertise in {skills} and {experience} background, looking to contribute to high-impact projects.",
        "Strategic {position} with {years}+ years of experience in {industry}, seeking to advance my career with a forward-thinking organization.",
        "Innovative {position} with demonstrated success in {achievement}, looking to bring my expertise to a dynamic team."
    ]

    # Get positions based on branch
    positions_by_branch = {
        "CSE": ["Software Engineer", "Full Stack Developer", "Backend Developer", "DevOps Engineer", "Technology Specialist"],
        "IT": ["Software Developer", "Systems Engineer", "IT Specialist", "Cloud Engineer", "Security Analyst"],
        "ECE": ["Electronics Engineer", "Embedded Systems Engineer", "Hardware Designer", "IoT Developer", "VLSI Engineer"],
        "EE": ["Electrical Engineer", "Power Systems Engineer", "Control Systems Engineer", "Energy Management Specialist"],
        "Mechanical": ["Mechanical Engineer", "Design Engineer", "Product Development Engineer", "CAD Specialist"],
        "Civil": ["Civil Engineer", "Structural Engineer", "Construction Manager", "Project Engineer"],
        "Chemical": ["Chemical Engineer", "Process Engineer", "Production Engineer", "Quality Control Specialist"],
        "Automobile": ["Automotive Engineer", "Vehicle Design Engineer", "Powertrain Specialist"],
        "Petroleum": ["Petroleum Engineer", "Reservoir Engineer", "Production Engineer"],
        "Maths & Computing": ["Data Scientist", "Quantitative Analyst", "Algorithm Engineer", "Machine Learning Engineer"]
    }

    # Get default positions if branch not in map
    default_positions = ["Engineering Professional", "Technical Specialist", "Project Engineer"]
    positions = positions_by_branch.get(branch, default_positions)
    position = random.choice(positions)

    # Skills based on branch
    skills_by_branch = {
        "CSE": ["programming", "software development", "algorithm design", "full-stack", "cloud computing"],
        "IT": ["systems", "networking", "cloud", "security", "IT infrastructure"],
        "ECE": ["hardware", "embedded systems", "circuit design", "signal processing", "IoT"],
        "EE": ["power systems", "electrical design", "control systems", "energy management"],
        "Mechanical": ["mechanical design", "CAD", "thermodynamics", "material science", "robotics"],
        "Civil": ["structural analysis", "construction management", "design", "project planning"],
        "Chemical": ["process engineering", "chemical analysis", "plant operations", "simulation"],
        "Automobile": ["vehicle dynamics", "powertrain design", "automotive systems"],
        "Petroleum": ["reservoir engineering", "production optimization", "drilling technology"],
        "Maths & Computing": ["data analysis", "machine learning", "algorithm design", "statistical modeling"]
    }

    # Default skills if branch not in map
    default_skills = ["technical", "analytical", "engineering", "problem-solving"]
    branch_skills = skills_by_branch.get(branch, default_skills)

    if has_experience:
        template = random.choice(professional_objectives)

        return template.format(
            position=position,
            years=random.randint(2, 6),
            skills=", ".join(random.sample(branch_skills, min(2, len(branch_skills)))),
            solutions=random.choice(["scalable", "enterprise", "data-driven", "customer-focused", "cloud-based", "innovative", "high-performance"]),
            field=random.choice(["software development", "cloud computing", "data science", "machine learning", "web development", "IoT", "automation", "analytics"]),
            experience=random.choice(["industry", "academic", "research", "startup", "enterprise", "consulting", "product development"]),
            industry=random.choice(["technology", "finance", "healthcare", "e-commerce", "telecommunications", "manufacturing", "energy", "automotive"]),
            achievement=random.choice([
                "developing high-performance applications",
                "optimizing system architecture",
                "implementing machine learning solutions",
                "leading cross-functional teams",
                "building scalable cloud infrastructure",
                "delivering enterprise-grade software",
                "designing innovative hardware solutions",
                "revolutionizing process efficiency"
            ])
        )
    else:
        template = random.choice(student_objectives)

        # Extract just the degree type without branch specifics
        degree_short = degree_type.split("in")[0].strip() if "in" in degree_type else degree_type

        return template.format(
            position=position,
            skills=random.choice(branch_skills),
            degree=degree_short,
            academic=random.choice(["strong", "comprehensive", "technical", "interdisciplinary", "specialized", "analytical"]),
            projects=random.choice(["hands-on", "academic", "personal", "team-based", "industry-focused", "innovative"]),
            field=random.choice(["software development", "data science", "cloud computing", "web development", "mobile applications", "IoT", "automation", "hardware design", "systems engineering"])
        )

def format_resume_as_text(resume):
    """Create a formatted text version of the resume with improved structure"""
    text = f"{resume['Personal Information']['Name'].upper()}\n"
    text += f"Email: {resume['Personal Information']['Email']} | Phone: {resume['Personal Information']['Phone']}\n"

    if len(resume['Personal Information']['GitHub']) + len(resume['Personal Information']['LinkedIn']) < 60:
        text += f"GitHub: {resume['Personal Information']['GitHub']} | LinkedIn: {resume['Personal Information']['LinkedIn']}\n\n"
    else:
        text += f"GitHub: {resume['Personal Information']['GitHub']}\n"
        text += f"LinkedIn: {resume['Personal Information']['LinkedIn']}\n\n"

    if "Objective" in resume:
        text += "CAREER OBJECTIVE\n"
        text += f"{resume['Objective']}\n\n"

    text += "EDUCATION\n"
    college = resume['Education']['College']
    text += f"{college['Institution']} ({college['Year']})\n"
    text += f"{college['Degree']}, CPI: {college['CPI']}"

    if "Branch" in college:
        text += f", Branch: {college['Branch']}"
    text += "\n"

    if len(college['Technical Courses']) < 70:
        text += f"Technical Courses: {college['Technical Courses']}\n"
    else:
        text += f"Technical Courses: {college['Technical Courses'][:67]}...\n"

    if "School" in resume['Education']:
        school = resume['Education']['School']
        text += f"{school['Institution']} ({school['Year']})\n"
        text += f"{school['Degree']}, Percentage: {school['Percentage']}%\n"

    text += "\n"

    if "Work Experience" in resume and resume["Work Experience"]:
        text += "WORK EXPERIENCE\n"
        for exp in resume["Work Experience"]:
            text += f"{exp['Job Title']} at {exp['Company']} ({exp['Duration']})\n"
            for resp in exp["Responsibilities"]:
                text += f"â€¢ {resp}\n"
            text += f"Technologies: {', '.join(exp['Technologies'])}\n\n"

    if "Projects" in resume and resume["Projects"]:
        text += "PROJECTS\n"
        for project in resume["Projects"]:
            text += f"{project['Title']} ({project['Duration']}){project['Team Size']}\n"
            text += f"â€¢ {project['Description']} {project['Impact']}\n"
            for accomplishment in project["Accomplishments"]:
                text += f"â€¢ {accomplishment}\n"
            text += f"Technologies: {project['Tools']}\n\n"

    if "Technical Skills" in resume:
        skills = resume["Technical Skills"]
        text += "TECHNICAL SKILLS\n"
        text += f"â€¢ Programming Languages: {', '.join(skills['Programming Languages'])}\n"
        text += f"â€¢ Frameworks & Libraries: {', '.join(skills['Frameworks & Libraries'])}\n"
        text += f"â€¢ Databases: {', '.join(skills['Databases'])}\n"
        text += f"â€¢ Professional Skills: {', '.join(skills['Professional Skills'])}\n"

        if skills["Competitive Programming"]:
            comp = skills["Competitive Programming"]
            text += f"â€¢ {comp['Platform']}: {comp['Rank']} with {comp['Problems Solved']}+ problems solved"
            if comp["Achievements"]:
                text += f" ({', '.join(comp['Achievements'])})"
            text += "\n"

        if skills["Certifications"]:
            text += f"â€¢ Certifications: {', '.join(skills['Certifications'])}\n"

        text += "\n"

    # Add Non-Programming Skills section
    if "Non-Programming Skills" in resume and resume["Non-Programming Skills"]:
        skills = resume["Non-Programming Skills"]
        text += "NON-PROGRAMMING SKILLS\n"

        # Display each category of non-programming skills
        for category, skill_list in skills["Categories"].items():
            text += f"â€¢ {category}: {', '.join(skill_list)}\n"

        # Certifications (if present)
        if "Certifications" in skills and skills["Certifications"]:
            text += f"â€¢ Certifications: {', '.join(skills['Certifications'])}\n"

        text += "\n"

    # Add Extracurricular Activities
    if "Extracurricular" in resume:
        text += "EXTRACURRICULAR ACTIVITIES\n"
        for activity in resume["Extracurricular"]:
            text += f"â€¢ {activity}\n"
        text += "\n"

    # Add Hobbies
    if "Hobbies" in resume:
        text += "HOBBIES\n"
        for hobby in resume["Hobbies"]:
            text += f"â€¢ {hobby}\n"

    return text

def generate_random_resumes(count=1):
    """Generate random resumes with coherent information based on engineering branches"""
    resumes = []

    for _ in range(count):
        # Generate personal information
        name = random.choice(first_names) + " " + random.choice(last_names)
        email = name.lower().replace(" ", ".") + "@" + random.choice(email_domains)
        phone = f"+91 {random.randint(7000000000, 9999999999)}"
        github = generate_github_link(name)
        linkedin = generate_linkedin_link(name)

        # Randomly choose an engineering branch or other field
        is_engineering = random.random() < 0.8  # 80% chance of engineering

        if is_engineering:
            branch = random.choice(list(engineering_branches.keys()))
            degree = random.choice(engineering_branches[branch])
        else:
            branch = None
            degree = random.choice(other_degrees)

        # Generate education with coherent courses
        college_institution = random.choice(institutions)
        college_year = random.choice(years_college)
        college_cpi = round(random.uniform(7.0, 9.8), 1)

        if branch:
            college_courses = ", ".join(get_courses_for_branch(branch, random.randint(4, 6)))
        else:
            # For non-engineering degrees, just use general courses
            college_courses = ", ".join(random.sample(courses_by_branch["CSE"] + math_courses, random.randint(3, 5)))

        # Generate projects with probability based on branch
        # Higher probability for CS/IT students
        if branch in ["CSE", "IT", "ECE", "Maths & Computing"]:
            has_projects_prob = 0.85
        else:
            has_projects_prob = 0.6

        has_projects = random.random() < has_projects_prob

        if has_projects:
            if branch:
                projects = generate_projects_for_branch(branch)
            else:
                # For non-engineering degrees, generate more general projects
                projects = generate_projects_for_branch(random.choice(["CSE", "IT", "Maths & Computing"]))
        else:
            projects = []

        # Extract project tools for skills
        project_tools = [p["Tools"] for p in projects] if projects else None

        # Generate technical skills based on branch and projects
        if branch:
            technical_skills = generate_technical_skills(branch, has_projects, project_tools)
        else:
            # For non-engineering degrees, generate more general technical skills
            technical_skills = generate_technical_skills("CSE", has_projects, project_tools)

        # Generate work experience based on graduation year and branch
        graduation_year = college_year.split("-")[1]
        if branch:
            work_experience = generate_work_experience(branch, college_year)
        else:
            work_experience = generate_work_experience("CSE", college_year)

        has_experience = len(work_experience) > 0

        # Generate objective based on experience and branch
        objective = generate_objective(branch if branch else "CSE", has_experience, degree)

        # Generate non-programming skills based on branch
        non_programming_skills = generate_non_programming_skills(branch if branch else "CSE")

        # Generate extracurricular activities (70% chance)
        has_extracurricular = random.random() < 0.7
        extracurricular_activities = []

        if has_extracurricular:
            num_activities = random.randint(1, 3)
            extracurricular_activities = random.sample(extracurricular, num_activities)

        # Generate hobbies (60% chance)
        has_hobbies = random.random() < 0.6
        hobby_list = []

        if has_hobbies:
            num_hobbies = random.randint(1, 3)
            hobby_list = random.sample(hobbies, num_hobbies)

        # Assemble the resume
        resume = {
            "Personal Information": {
                "Name": name,
                "Email": email,
                "Phone": phone,
                "GitHub": github,
                "LinkedIn": linkedin
            },
            "Education": {
                "College": {
                    "Institution": college_institution,
                    "Year": college_year,
                    "Degree": degree,
                    "Branch": branch if branch else None,
                    "CPI": college_cpi,
                    "Technical Courses": college_courses
                }
            },
            "Objective": objective
        }

        # Add school education (80% chance)
        if random.random() < 0.8:
            school_institution = random.choice(schools)
            school_year = int(college_year.split("-")[0]) - random.randint(3, 5)
            school_percentage = random.randint(85, 98)

            resume["Education"]["School"] = {
                "Institution": school_institution,
                "Year": school_year,
                "Degree": "Higher Secondary Education",
                "Percentage": school_percentage
            }

        # Add work experience if generated
        if work_experience:
            resume["Work Experience"] = work_experience

        # Add projects if generated
        if projects:
            resume["Projects"] = projects

        # Add skills if generated
        resume["Technical Skills"] = technical_skills
        resume["Non-Programming Skills"] = non_programming_skills

        # Add extracurricular activities if generated
        if extracurricular_activities:
            resume["Extracurricular"] = extracurricular_activities

        # Add hobbies if generated
        if hobby_list:
            resume["Hobbies"] = hobby_list

        # Format the resume as text
        resume_text = format_resume_as_text(resume)
        resume["Text"] = resume_text

        resumes.append(resume)

    return resumes

# Example usage
if __name__ == "__main__":
    # Generate random resumes
    resumes = generate_random_resumes(1000)

    # Save to JSON file
    with open("generated_resumes.json", "w") as f:
        json.dump(resumes, f, indent=2)

    # Print a sample resume
    print("Sample Resume:")
    print(resumes[0]["Text"])
    print(f"Successfully generated {len(resumes)} realistic resumes!")

"""# Resume Parser code for generated resumes"""

import json
import pandas as pd
import re

def parse_resumes(file_path, company_skills_data=None):
    """
    Parse resume JSON data into a structured DataFrame

    Args:
        file_path: Path to the JSON file containing resume data
        company_skills_data: DataFrame containing company skill requirements (optional)

    Returns:
        DataFrame with parsed resume information
    """
    with open(file_path, 'r') as f:
        resumes = json.load(f)

    # Create a set of company required skills if available
    company_skill_set = set()
    if company_skills_data is not None:
        # Assuming company_skills_data has a 'Skills' column
        for skills in company_skills_data['Skills']:
            if isinstance(skills, str):
                company_skill_set.update([s.strip().lower() for s in skills.split(',')])

    parsed_data = []

    for resume in resumes:
        # Extract education information
        education = resume['Education']['College']

        # Extract GPA/CPI and percentage
        cpi_gpa = education.get('CPI', None)

        # Extract percentage from school if available
        percentage = None
        if 'School' in resume['Education']:
            percentage = resume['Education']['School'].get('Percentage', None)

        # Extract branch information
        branch = education.get('Branch', None)
        if not branch:
            # Try to extract branch from degree
            degree = education.get('Degree', '')
            # Common branch abbreviations and full names
            branch_patterns = {
                'CSE': r'Computer Science|CSE',
                'IT': r'\bIT\b|Information Technology',
                'ECE': r'Electronics|Communication|ECE',
                'EE': r'Electrical|EE',
                'ME': r'Mechanical|ME',
                'Civil': r'Civil',
                'Chemical': r'Chemical',
                'Automobile': r'Automobile|Automotive',
                'Petroleum': r'Petroleum',
                'Maths & Computing': r'Mathematics|Computing|Maths'
            }

            for branch_name, pattern in branch_patterns.items():
                if re.search(pattern, degree, re.IGNORECASE):
                    branch = branch_name
                    break

        # Get Technical Skills or use empty dict as default
        tech_skills = resume.get('Technical Skills', {})

        # Extract all skills
        all_skills = []
        for category in ['Programming Languages', 'Frameworks & Libraries', 'Databases', 'Professional Skills']:
            if category in tech_skills:
                all_skills.extend(tech_skills[category])

        # Compare with company skills if available
        matching_skills = []
        if company_skill_set:
            for skill in all_skills:
                if skill.lower() in company_skill_set:
                    matching_skills.append(skill)
        else:
            matching_skills = all_skills  # If no company skills provided, use all skills

        # Extract core computer skills (programming languages, frameworks, databases)
        core_skills = extract_core_skills(tech_skills)

        # Extract projects information
        projects = resume.get('Projects', [])
        num_projects = len(projects)

        # Extract project keywords
        project_keywords = extract_project_keywords(projects, company_skill_set)

        # Check for work experience
        has_experience = 'Yes' if 'Work Experience' in resume and resume['Work Experience'] else 'No'

        parsed_resume = {
            'CPI/GPA': cpi_gpa,
            'Percentage': percentage,
            'Skills': ', '.join(matching_skills),
            'Branch': branch,
            'No. of Projects': num_projects,
            'Project Keywords': project_keywords,
            'Mobile Number': resume['Personal Information']['Phone'],
            'Email ID': resume['Personal Information']['Email'],
            'Has Experience': has_experience,
            'Core Computer Skills': core_skills
        }
        parsed_data.append(parsed_resume)

    return pd.DataFrame(parsed_data)

def extract_project_keywords(projects, company_skill_set=None):
    """
    Extract relevant keywords from projects

    Args:
        projects: List of project dictionaries
        company_skill_set: Set of skills required by companies (optional)

    Returns:
        String of comma-separated keywords
    """
    keywords = set()

    for project in projects:
        # Extract category/domain
        if 'Category' in project:
            keywords.add(project['Category'])

        # Extract tools and technologies
        if 'Tools' in project:
            tools = [tool.strip() for tool in project['Tools'].split(',')]
            keywords.update(tools)

        # Extract keywords from description and accomplishments
        for field in ['Description', 'Impact']:
            if field in project:
                text = project[field]
                # Extract technical terms (simplified approach)
                potential_keywords = re.findall(r'\b[A-Za-z][\w\+\#\.-]+\b', text)
                keywords.update(potential_keywords)

        if 'Accomplishments' in project:
            for acc in project['Accomplishments']:
                potential_keywords = re.findall(r'\b[A-Za-z][\w\+\#\.-]+\b', acc)
                keywords.update(potential_keywords)

    # Filter keywords if company_skill_set is provided
    if company_skill_set:
        filtered_keywords = {k for k in keywords if k.lower() in company_skill_set}
        return ', '.join(filtered_keywords)

    return ', '.join(keywords)

def extract_core_skills(skills):
    """
    Extract core computer skills from technical skills

    Args:
        skills: Dictionary of technical skills

    Returns:
        String of comma-separated core skills
    """
    core_skills = set()

    # Core technical categories
    core_categories = ['Programming Languages', 'Frameworks & Libraries', 'Databases', 'DevOps', 'Testing']

    for category in core_categories:
        if category in skills:
            core_skills.update(skills[category])

    # Add competitive programming info if available
    if 'Competitive Programming' in skills and skills['Competitive Programming']:
        platform = skills['Competitive Programming']['Platform']
        rank = skills['Competitive Programming']['Rank']
        core_skills.add(f"{platform} ({rank})")

    return ', '.join(core_skills)

# Example usage
# Assuming you have a DataFrame with company skill requirements
# company_skills_df = pd.read_excel('BTech_Companies_NLP.xlsx')
# file_path = 'generated_resumes.json'
# df = parse_resumes(file_path, company_skills_df)

# Without company skills data
file_path = 'generated_resumes.json'
df = parse_resumes(file_path)
print(df.head())

df.shape

"""# PDF Resume Parser"""

import os
import re
import pandas as pd
import numpy as np
from PyPDF2 import PdfReader
import spacy
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import string

# Download necessary NLTK resources
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)

# Load spaCy model
try:
    nlp = spacy.load('en_core_web_sm')
except:
    # Install if not available
    print("Downloading spaCy model...")
    !python -m spacy download en_core_web_sm
    nlp = spacy.load('en_core_web_sm')

class EnhancedResumeParser:
    def __init__(self):
        # Define skill set list from provided data
        self.skill_set_list = [
            # Programming Languages
            'java', 'python', 'c++', 'c#', 'javascript', 'html', 'css', 'php', 'sql', 'r', 'apex',
            'swift', 'kotlin', 'rust', 'typescript', 'perl', 'scala', 'go', 'ruby', 'matlab',
            # Tools and Frameworks
            'aws', 'amazon web services', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins',
            'git', 'react', 'angular', 'vue', 'node.js', 'express', 'django', 'flask', 'spring boot',
            'hibernate', 'asp.net', '.net', 'tensorflow', 'pytorch', 'keras', 'salesforce',
            'tableau', 'power bi', 'excel', 'microsoft excel',
            # Databases
            'mysql', 'postgresql', 'mongodb', 'oracle', 'cassandra', 'redis', 'sqlite',
            # Concepts
            'artificial intelligence', 'ai', 'machine learning', 'ml', 'data science',
            'deep learning', 'natural language processing', 'nlp', 'computer vision',
            'cloud computing', 'devops', 'development operations', 'automation', 'cybersecurity',
            'networking', 'data analysis', 'data structures', 'algorithms', 'oop', 'object-oriented programming',
            'database management', 'embedded systems', 'internet of things', 'iot', 'rest api',
            'web development', 'full-stack', 'front-end', 'back-end', 'agile', 'scrum',
            'user interface', 'ui', 'user experience', 'ux', 'testing', 'qa', 'quality assurance',
            'security', 'risk analysis', 'risk management', 'data analytics', 'big data',
            'business intelligence', 'seo', 'sem', 'digital marketing', 'consulting', 'audit',
            'finance', 'banking', 'automotive', 'electrical engineering', 'mechanical engineering',
            'civil engineering', 'chemical engineering', 'petroleum engineering',
            # Domain-specific
            'consulting', 'automobile engineering', 'banking', 'information technology',
            'chemical engineering', 'civil', 'mechanical', 'cloud computing', 'cybersecurity',
            'data analysis', 'structured query language', 'embedded systems', 'energy',
            'finance', 'risk analysis', 'trading', 'gas pipeline engineering', 'salesforce lightning',
            'salesforce visualforce', 'digital transformation', 'business analysis',
            'strategic planning', 'process improvement', 'technical consulting', 'troubleshooting',
            'system integration', 'design thinking', 'prototyping', 'engineering fundamentals',
            'process engineering', 'research', 'technical analysis', 'communication', 'curriculum design',
            'teaching', 'analytical skills', 'computer-aided design', 'teamwork', 'client management',
            'coordination', 'electrical engineering', 'product development', 'market research',
            'credit risk', 'financial modeling', 'advanced programming', 'digital solutions',
            'electronics design', 'circuit analysis', 'debugging', 'business development', 'sales',
            'engineering', 'metallurgy', 'technical problem solving', 'engineering skills',
            'technical design', 'project management', 'technical proficiency', 'automotive technology',
            'threat analysis', 'information technology infrastructure', 'system administration',
            'system programming', 'operating system', 'graphics processing unit', 'gpu',
            'search engine optimization', 'seo', 'search engine marketing', 'sem', 'revenue management',
            'research and development', 'innovation', 'android development', 'software/hardware integration',
            'object-oriented programming', 'process optimization', 'system design', 'information technology strategy',
            'digital transformation', 'enterprise architecture', 'power systems', 'html', 'cascading style sheets', 'css',
            'responsive design', 'industrial automation', 'rest application programming interfaces',
            'representational state transfer', 'marketing', 'networking', 'node.js', 'django',
            'oil and gas', 'power systems'
        ]

        # Organize skills into categories for better recognition
        self.skill_categories = {
            'programming_languages': ['java', 'python', 'c++', 'c#', 'javascript', 'typescript', 'php', 'ruby', 'perl',
                                     'scala', 'swift', 'kotlin', 'r', 'matlab', 'go', 'rust', 'cobol', 'fortran', 'bash',
                                     'powershell', 'assembly', 'lisp', 'prolog', 'dart', 'apex'],

            'web_development': ['html', 'css', 'javascript', 'react', 'angular', 'vue', 'django', 'flask', 'node.js',
                               'express', 'php', 'laravel', 'symfony', 'ruby on rails', 'bootstrap', 'jquery', 'asp.net',
                               'spring mvc', 'wordpress', 'gatsby', 'sass', 'less', 'webpack', 'babel'],

            'data_science': ['python', 'r', 'sql', 'tensorflow', 'pytorch', 'keras', 'scikit-learn', 'pandas', 'numpy',
                            'matplotlib', 'seaborn', 'tableau', 'power bi', 'excel', 'spss', 'sas', 'hadoop', 'spark',
                            'big data', 'data mining', 'data analytics', 'statistical analysis', 'machine learning', 'ai',
                            'deep learning', 'nlp', 'computer vision'],

            'databases': ['sql', 'mysql', 'postgresql', 'oracle', 'sql server', 'mongodb', 'cassandra', 'redis',
                         'dynamodb', 'firebase', 'neo4j', 'sqlite', 'mariadb', 'couchdb', 'dbms', 'database management'],

            'cloud_devops': ['aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'git', 'github', 'gitlab',
                            'terraform', 'ansible', 'puppet', 'chef', 'bitbucket', 'jira', 'confluence', 'ci/cd',
                            'cloud computing', 'devops', 'microservices', 'serverless'],

            'mobile_development': ['android', 'ios', 'swift', 'kotlin', 'flutter', 'react native', 'xamarin',
                                  'mobile app development', 'objective-c', 'cordova', 'ionic'],

            'system_concepts': ['algorithms', 'data structures', 'oop', 'design patterns', 'architecture', 'system design',
                               'microservices', 'restful api', 'soap', 'graphql', 'mvc', 'mvvm', 'operating systems',
                               'networking', 'distributed systems', 'concurrency', 'multithreading', 'memory management'],

            'cybersecurity': ['security', 'encryption', 'cryptography', 'penetration testing', 'ethical hacking',
                             'firewall', 'vpn', 'intrusion detection', 'malware analysis', 'siem', 'forensics',
                             'cybersecurity', 'network security', 'authentication', 'authorization'],

            'business_finance': ['finance', 'accounting', 'banking', 'trading', 'investment', 'risk management',
                                'credit risk', 'financial modeling', 'fintech', 'blockchain', 'cryptocurrency',
                                'consulting', 'audit', 'compliance', 'business analysis', 'strategic planning']
        }

        # Add project keywords from the provided data
        self.project_keywords_list = [
            'ai', 'ml', 'rpa', 'python', 'automation', 'audit', 'financial analysis', 'risk assessment',
            'cad', 'solidworks', 'vehicle dynamics', 'dsa', 'java', 'aws', 'system design', 'data analysis',
            'finance', 'sql', 'risk analysis', 'tech', 'data security', 'chemical simulation', 'matlab',
            'oil & gas', 'structural design', 'autocad', 'construction', 'azure', '.net', 'javascript',
            'kubernetes', 'devops', 'docker', 'cloud', 'web dev', 'react', 'business analysis', 'excel',
            'power bi', 'networking', 'cybersecurity', 'firewalls', 'r', 'big data', 'oop', 'software development',
            'competitive programming', 'dbms', 'oracle', 'embedded c', 'hardware', 'iot', 'fpga', 'microcontrollers',
            'vlsi', 'renewable energy', 'scada', 'data visualization', 'tableau', 'fintech', 'quantitative analysis',
            'risk modeling', 'risk assessment', 'investment banking', 'power systems', 'electrical engineering',
            'salesforce', 'crm', 'apex programming', 'full stack', 'digital strategy', 'analytics', 'it consulting',
            'business strategy', 'process optimization', 'it systems', 'technical support', 'erp', 'energytech',
            'system design', 'research', 'visualization', 'debugging', 'git', 'software dev', 'prototyping',
            'design thinking', 'ux research', 'process engineering', 'industrial safety', 'technical research',
            'wireless networks', 'telecom', 'curriculum design', 'teaching', 'problem-solving', 'mechanical design',
            'engineering design', 'product development', 'client communication', 'market analysis', 'control systems',
            'market research', 'credit risk', 'agile development', 'full-stack', 'process safety', 'pcb design',
            'debugging', 'sdlc', 'sales strategies', 'metallurgical analysis', 'material science', 'material testing',
            'civil engineering', 'construction management', 'automotive engineering', 'automotive software',
            'business intelligence', 'political analytics', 'business operations', 'network security', 'ethical hacking',
            'siem', 'cloud computing', 'system administration', 'cuda', 'gpu computing', 'os', 'seo', 'sem',
            'google ads', 'marketing analytics', 'revenue optimization', 'teaching skills', 'curriculum development',
            'r&d', 'innovation', 'engineering design', 'android', 'kotlin', 'ui/ux', 'software-hardware integration',
            'financial modeling', 'algorithm', 'c++', 'data analysis', 'electrical', 'power systems', 'energy engineering',
            'project planning', 'customer service', 'territory management', 'html', 'css', 'responsive design',
            'industrial automation', 'robotics', 'embedded systems', 'ai/ml', 'software engineering', 'rest apis',
            'r&d', 'software development', 'data analysis', 'system design', 'web development', 'testing',
            'marketing', 'product design', 'it solutions', 'sql', 'chemical engineering', 'petroleum engineering',
            'energy', 'dsa', 'algorithms', 'system design', 'software development', 'software engineering',
            'risk management', 'banking', 'finance', 'sap', 'consulting', 'it services', 'qa', 'digital design',
            'javascript'
        ]

        # Branch mapping with standardized names and aliases
        self.branch_mapping = {
            'Computer Science': ['cse', 'computer science', 'computer science and engineering', 'cs', 'computer',
                                'computer engineering', 'software engineering', 'computation', 'computing'],
            'Information Technology': ['it', 'information technology', 'information systems', 'information science'],
            'Electronics and Communication': ['ece', 'electronics and communication', 'electronics', 'communication engineering',
                                             'electronics and communication engineering', 'electronic engineering'],
            'Electrical Engineering': ['ee', 'electrical', 'electrical engineering', 'electrical and electronics',
                                      'eee', 'electrical and electronics engineering', 'power systems'],
            'Mechanical Engineering': ['mech', 'mechanical', 'mechanical engineering', 'mechanics'],
            'Civil Engineering': ['civil', 'civil engineering', 'structural engineering'],
            'Chemical Engineering': ['chem', 'chemical', 'chemical engineering', 'chemistry engineering'],
            'Petroleum Engineering': ['petroleum', 'petro', 'petroleum engineering', 'oil and gas'],
            'Aerospace Engineering': ['aerospace', 'aeronautical', 'aeronautical engineering', 'aerospace engineering'],
            'Automobile Engineering': ['automobile', 'automotive engineering', 'automotive'],
            'Mathematics and Computing': ['maths & computing', 'mathematics and computing', 'mathematical computing',
                                         'math and cs', 'mathematics and computer science']
        }

        # Core computer skills mapping
        self.core_computer_skills = {
            'OS': ['operating system', 'os', 'windows', 'linux', 'unix', 'macos', 'android', 'ios', 'embedded os',
                  'real-time os', 'rtos', 'operating systems', 'system administration'],
            'Networks': ['networking', 'network', 'tcp/ip', 'dns', 'dhcp', 'router', 'switch', 'firewall', 'vpn',
                        'lan', 'wan', 'network security', 'network administration', 'cisco', 'network architecture'],
            'DBMS': ['database management system', 'dbms', 'sql', 'mysql', 'postgresql', 'oracle', 'mongodb',
                    'database design', 'er diagram', 'normalization', 'acid', 'transaction', 'sql server', 'nosql',
                    'database administration', 'data modeling'],
            'OOP': ['object oriented programming', 'oop', 'object-oriented', 'inheritance', 'polymorphism',
                   'encapsulation', 'abstraction', 'class', 'object', 'java', 'c++', 'c#', 'design patterns'],
            'Computer Architecture': ['computer architecture', 'processor design', 'memory hierarchy', 'cache',
                                    'pipelining', 'instruction sets', 'cpu', 'alu', 'von neumann', 'harvard architecture',
                                    'risc', 'cisc', 'assembly language', 'microprocessors']
        }

        # Improved CGPA/GPA patterns
        self.gpa_patterns = [
            r'(?:cgpa|cpi|gpa)\s*[:/]?\s*(\d+\.\d+)[/\s]*\d+',
            r'(?:cgpa|cpi|gpa)(?:\s*|\:)(\d+\.\d+)',
            r'(\d+\.\d+)\s*\/\s*10',
            r'(\d+\.\d+)(?:\s*/\s*|\s+out\s+of\s+)(?:10|4)',
            r'(\d+\.\d+)[/]?[10]?',
            r'cgpa\s*[-:/]?\s*(\d+\.\d+)',
            r'(\d+\.\d+)\s*/\s*10',
            r'(?<=cgpa).*?(\d+\.\d+)',
            r'(?<=cpi).*?(\d+\.\d+)',
            r'(?<=gpa).*?(\d+\.\d+)',
            r'\b(\d+\.\d+)\/10\b',
            r'upto\s+\d+\/10\s+sem\)?[\s:]*(\d+\.\d+)\/10',
            r'awarded\s+grade\s+(\d+)\/10'
        ]

        # Specific patterns for tables in academic sections
        self.table_gpa_patterns = [
            r'(?:cgpa|cpi|gpa)[^\d]*(\d+\.\d+)\/10',
            r'(\d+\.\d+)\/10',
            r'grade\s+(\d+)\/10'
        ]

        self.email_pattern = r'[\w\.-]+@[\w\.-]+\.\w+'

        self.phone_patterns = [
            r'(?:\+\d{1,3}[-.\s]?)?\(?\d{3,4}\)?[-.\s]?\d{3}[-.\s]?\d{4}',
            r'(?:\+\d{1,3}[-.\s]?)?\d{10,12}',
            r'(?:\+\d{1,3}[-.\s]?)?\d{3,4}[-.\s]?\d{3}[-.\s]?\d{4}'
        ]

        # Convert all lists to lowercase for case-insensitive matching
        self.skill_set_list = [skill.lower() for skill in self.skill_set_list]
        self.project_keywords_list = [keyword.lower() for keyword in self.project_keywords_list]

        for category in self.skill_categories:
            self.skill_categories[category] = [skill.lower() for skill in self.skill_categories[category]]

        for branch, aliases in self.branch_mapping.items():
            self.branch_mapping[branch] = [alias.lower() for alias in aliases]

        for skill, keywords in self.core_computer_skills.items():
            self.core_computer_skills[skill] = [keyword.lower() for keyword in keywords]

    def preprocess_text(self, text):
        """Preprocess text for better matching"""
        if not text:
            return ""

        # Convert to lowercase
        text = text.lower()

        # Replace special characters with space
        text = re.sub(r'[^\w\s]', ' ', text)

        # Replace multiple spaces with a single space
        text = re.sub(r'\s+', ' ', text)

        return text.strip()

    def extract_text_from_pdf(self, pdf_path):
        """Extract text from a PDF file"""
        try:
            reader = PdfReader(pdf_path)
            text = ""
            for page in reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            print(f"Error extracting text from {pdf_path}: {e}")
            return ""

    # [All the other methods remain the same]

    def extract_gpa(self, text):
        """Extract GPA/CGPA from text with improved accuracy"""
        text = text.lower()

        # First look for academic/education sections
        academic_section_patterns = [
            r'academic(?:\s+profile|\s+qualifications?)(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'education(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:qualification|degree)(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)'
        ]

        academic_sections = []
        for pattern in academic_section_patterns:
            sections = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            academic_sections.extend(sections)

        # Create a combined section text
        section_text = "\n".join(academic_sections) if academic_sections else text

        # Try table patterns first in academic sections
        for pattern in self.table_gpa_patterns:
            match = re.search(pattern, section_text, re.IGNORECASE)
            if match:
                try:
                    gpa = float(match.group(1))
                    return gpa
                except ValueError:
                    continue

        # Try all patterns in academic sections
        for pattern in self.gpa_patterns:
            match = re.search(pattern, section_text, re.IGNORECASE)
            if match:
                try:
                    gpa = float(match.group(1))
                    # Convert if it looks like a 4.0 scale
                    if gpa <= 4.0 and gpa > 0 and '/4' in section_text:
                        return gpa * 2.5
                    return gpa
                except ValueError:
                    continue

        # If not found in academic sections, try the full text
        for pattern in self.gpa_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    gpa = float(match.group(1))
                    # Convert if it looks like a 4.0 scale
                    if gpa <= 4.0 and gpa > 0 and '/4' in text:
                        return gpa * 2.5
                    return gpa
                except ValueError:
                    continue

        # Look for integers that might be CGPA as 10/10
        grade_match = re.search(r'grade\s+(\d+)\/10', text, re.IGNORECASE)
        if grade_match:
            try:
                return float(grade_match.group(1))
            except ValueError:
                pass

        return None

    # [Other extraction methods remain the same]
    def extract_skills(self, text):
        """Extract skills from text using improved matching algorithms"""
        text = self.preprocess_text(text)
        found_skills = set()
        doc = nlp(text)

        # 1. Extract skills explicitly mentioned in skills sections
        skills_section_patterns = [
            r'(?:technical\s+)?skills\s*:(.+?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:technical\s+)?skills(?:\s+include)?(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:technologies|programming\s+languages|languages|tools|frameworks|platforms)(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)'
        ]

        skills_sections = []
        for pattern in skills_section_patterns:
            sections = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            skills_sections.extend(sections)

        # Create a combined section text
        section_text = " ".join(skills_sections) if skills_sections else text

        # 2. Direct pattern matching for skills in our list
        for skill in self.skill_set_list:
            # Create a word boundary pattern and search
            if re.search(r'\b' + re.escape(skill) + r'\b', section_text, re.IGNORECASE):
                found_skills.add(skill)

        # 3. Use entity recognition for unlisted skills
        for sent in doc.sents:
            for token in sent:
                # Check for programming languages, technologies, and tools
                if token.pos_ in ['NOUN', 'PROPN'] and token.text.lower() not in stopwords.words('english'):
                    if token.text.lower() in self.skill_set_list:
                        found_skills.add(token.text.lower())
                    # Special handling for multi-word technologies
                    elif token.i < len(doc) - 1 and (token.text + " " + doc[token.i + 1].text).lower() in self.skill_set_list:
                        found_skills.add((token.text + " " + doc[token.i + 1].text).lower())

        # 4. Check for skills by category for better organization
        for category, category_skills in self.skill_categories.items():
            for skill in category_skills:
                if re.search(r'\b' + re.escape(skill) + r'\b', text, re.IGNORECASE):
                    found_skills.add(skill)

        return list(found_skills)

    def extract_branch(self, text):
      """Extract educational branch with improved precedence logic"""
      text = self.preprocess_text(text)

      # Extract education section
      education_section_patterns = [
          r'education(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
          r'academic(?:\s+qualification|\s+background)?(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
          r'qualification(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)'
      ]

      education_sections = []
      for pattern in education_section_patterns:
          sections = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
          education_sections.extend(sections)

      section_text = " ".join(education_sections) if education_sections else text

      # PRIORITY 1: Check for complete phrases in context of degree
      degree_context_patterns = [
          r'(?:bachelor|master|b\.tech|m\.tech|b\.e|m\.e|degree)[^\n]*(?:in|of)[^\n]*([\w\s&]+)',
          r'(?:major|specialization|branch|discipline)[^\n]*(?:in|of)[^\n]*([\w\s&]+)'
      ]

      for pattern in degree_context_patterns:
          matches = re.findall(pattern, section_text, re.IGNORECASE)
          for match in matches:
              match_text = match.strip().lower()
              # Check each branch with all its aliases
              for branch_name, aliases in self.branch_mapping.items():
                  for alias in aliases:
                      if alias in match_text:
                          # If multiple aliases match, pick the longest one to ensure specificity
                          if len(alias.split()) > 1:  # Multi-word match has priority
                              return branch_name

      # PRIORITY 2: Check for exact multi-word matches in branch aliases
      all_matched_branches = []
      for branch_name, aliases in self.branch_mapping.items():
          for alias in aliases:
              if len(alias.split()) > 1 and re.search(r'\b' + re.escape(alias) + r'\b', section_text, re.IGNORECASE):
                  all_matched_branches.append((branch_name, alias, len(alias)))

      # Sort matches by length of the alias (longer matches first)
      if all_matched_branches:
          all_matched_branches.sort(key=lambda x: x[2], reverse=True)
          return all_matched_branches[0][0]  # Return the branch with longest matching alias

      # PRIORITY 3: If still no match, then fall back to single-word matching
      all_single_matches = []
      for branch_name, aliases in self.branch_mapping.items():
          for alias in aliases:
              if len(alias.split()) == 1 and re.search(r'\b' + re.escape(alias) + r'\b', section_text, re.IGNORECASE):
                  all_single_matches.append((branch_name, alias))

      # If single matches found, prioritize Computer Science last (it's often a false positive)
      if all_single_matches:
          non_cs_matches = [match for match in all_single_matches if match[0] != 'Computer Science']
          if non_cs_matches:
              return non_cs_matches[0][0]
          return all_single_matches[0][0]

      # Default branch detection (if nothing else matched)
      return None

    def count_projects(self, text):
      """Advanced multi-strategy algorithm for precise project counting in diverse resume formats"""
      # Normalize text
      text = re.sub(r'\s+', ' ', text)
      text = text.replace('\n', ' <NL> ').lower()

      # STAGE 1: Document Structure Analysis
      # Extract project sections with flexible boundary detection
      project_section_patterns = [
          r'(?:<NL>|\s+|^)(?:projects?|academic\s+projects?|technical\s+projects?|selected\s+work)(?:\s*:|<NL>)(.*?)(?:<NL>\s*(?:[a-z0-9]*\s*[a-z]*\s*(?:education|experience|skills|achievements|awards|publications|certifications|references|activities|additional|interests|languages))|$)',
          r'(?:<NL>|\s+|^)(?:projects?\s+experience|project\s+work|portfolio|initiatives?)(?:\s*:|<NL>)(.*?)(?:<NL>\s*(?:[a-z0-9]*\s*[a-z]*\s*(?:education|experience|skills|achievements|awards|publications|certifications|references|activities|additional|interests|languages))|$)'
      ]

      project_section = None
      for pattern in project_section_patterns:
          match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
          if match:
              project_section = match.group(1)
              break

      analysis_text = project_section if project_section else text

      # STAGE 2: Multi-Strategy Detection with Weighted Confidence
      confidence_scores = {}

      # Strategy 1: Section Header Pattern Analysis (30% weight)
      header_patterns = [
          r'(?:<NL>|\s+)(?:m\.?tech|b\.?tech|undergraduate|master\'?s|senior|final\s+year)\s+project',
          r'(?:<NL>|\s+)design\s+lab',
          r'(?:<NL>|\s+)(?:research|course|major|minor|team)\s+project',
          r'(?:<NL>|\s+)project\s+\d+',
          r'(?:<NL>|\s+)capstone(?:\s+project)?'
      ]

      header_count = 0
      for pattern in header_patterns:
          matches = re.findall(pattern, analysis_text)
          header_count += len(matches)

      if header_count > 0:
          confidence_scores['section_header'] = (header_count, 0.30)

      # Strategy 2: Title-Year Pattern Matching (25% weight)
      title_patterns = [
          r'(?:<NL>|\s+)title\s*:\s*([^<NL>]{10,})',
          r'(?:<NL>|\s+)project\s*(?:title|name)\s*:\s*([^<NL>]{10,})',
          r'(?:<NL>|\s+|^)(?:[â€¢\*\-]\s*)?([A-Z][^<NL>]{10,})(?=<NL>|:\s*(?:20|19)\d{2}|,\s*(?:20|19)\d{2})'
      ]

      title_count = 0
      for pattern in title_patterns:
          matches = re.findall(pattern, analysis_text, re.IGNORECASE)
          title_count += len([t for t in matches if len(t.strip()) > 10 and not re.search(r'\b(?:january|february|march|april|may|june|july|august|september|october|november|december)\b', t.lower())])

      if title_count > 0:
          confidence_scores['title_year'] = (title_count, 0.25)

      # Strategy 3: Bullet Structure Pattern (20% weight)
      bullet_pattern = r'(?:<NL>\s*)[â€¢\*\-]\s+[^<NL>]+'
      bullet_matches = re.findall(bullet_pattern, analysis_text)

      # Group bullets into clusters by proximity
      bullet_clusters = []
      current_cluster = []
      last_pos = -1

      for bullet in bullet_matches:
          curr_pos = analysis_text.find(bullet)
          if last_pos == -1 or curr_pos - last_pos < 300:  # Close enough to be same project
              current_cluster.append(bullet)
          else:
              if len(current_cluster) >= 2:  # Need multiple bullets for a project
                  bullet_clusters.append(current_cluster)
              current_cluster = [bullet]
          last_pos = curr_pos + len(bullet)

      if current_cluster and len(current_cluster) >= 2:
          bullet_clusters.append(current_cluster)

      if bullet_clusters:
          bullet_count = len(bullet_clusters)
          confidence_scores['bullet_structure'] = (bullet_count, 0.20)

      # Strategy 4: Project Verb Analysis (15% weight)
      action_verbs = [
          r'\bdeveloped\b', r'\bimplemented\b', r'\bdesigned\b', r'\bcreated\b',
          r'\bbuilt\b', r'\bauthored\b', r'\bengineered\b', r'\bconducted\b',
          r'\barchitected\b', r'\bprogrammed\b', r'\bresearched\b', r'\banalyzed\b'
      ]

      verb_contexts = []
      for verb in action_verbs:
          contexts = re.findall(r'[^.!?<NL>]{5,100}' + verb + r'[^.!?<NL>]{5,100}', analysis_text)
          for context in contexts:
              if len(context) > 40:  # Substantial context
                  verb_contexts.append(context)

      # Deduplicate similar contexts
      unique_contexts = []
      for context in verb_contexts:
          if not any(self._text_similarity(context, existing) > 0.6 for existing in unique_contexts):
              unique_contexts.append(context)

      if unique_contexts:
          # Cap at reasonable number
          verb_count = min(len(unique_contexts), 8)
          confidence_scores['project_verbs'] = (verb_count, 0.15)

      # Strategy 5: Supervision/Guide Pattern (20% weight)
      guide_patterns = [
          r'(?:<NL>|\s+)(?:guide|supervisor|advisor)\s*:\s*(?:prof\.?|dr\.?)?',
          r'(?:<NL>|\s+)(?:mentor|professor|instructor)\s*:\s*'
      ]

      guide_count = 0
      for pattern in guide_patterns:
          guide_matches = re.findall(pattern, analysis_text)
          guide_count += len(guide_matches)

      if guide_count > 0:
          confidence_scores['guide_pattern'] = (guide_count, 0.20)

      # Strategy 6: Date Pattern Analysis (15% weight)
      date_patterns = [
          r'(?:<NL>|\s+)(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[a-z]*\s*\'?(?:\d{2}|\d{4})\s*-\s*(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|present|current|now)',
          r'(?:<NL>|\s+)(?:20|19)\d{2}\s*-\s*(?:(?:20|19)\d{2}|present|current|now)',
          r'(?:<NL>|\s+)(?:duration|period)\s*:\s*.*?(?:months?|years?)'
      ]

      date_count = 0
      for pattern in date_patterns:
          date_matches = re.findall(pattern, analysis_text)
          date_count += len(date_matches)

      if date_count > 0:
          confidence_scores['date_pattern'] = (date_count, 0.15)

      # Strategy 7: Structural Format Detection (30% weight)
      # This handles project formats with visual boundaries but without explicit markers
      block_pattern = r'(?:<NL>\s*<NL>|\s{3,}|[-_=]{3,})([^<NL>]{100,})(?:<NL>\s*<NL>|\s{3,}|[-_=]{3,})'
      block_matches = re.findall(block_pattern, analysis_text)

      project_blocks = 0
      for block in block_matches:
          score = 0
          # Check for project characteristics
          if re.search(r'\b(?:project|application|system|platform|software|website|mobile|tool)\b', block):
              score += 2
          if re.search(r'\b(?:developed|implemented|created|designed|built)\b', block):
              score += 2
          if re.search(r'\b(?:20|19)\d{2}\b', block):
              score += 1
          if re.search(r'\b(?:technology|framework|language|library|stack|database)\b', block):
              score += 1

          if score >= 3:
              project_blocks += 1

      if project_blocks > 0:
          confidence_scores['structural_format'] = (project_blocks, 0.30)

      # STAGE 3: Make final decision with weighted confidence
      if confidence_scores:
          # Calculate weighted average
          weighted_sum = 0
          total_weight = 0

          for strategy, (count, weight) in confidence_scores.items():
              weighted_sum += count * weight
              total_weight += weight

          if total_weight > 0:
              weighted_avg = weighted_sum / total_weight
              # Round to nearest integer
              project_count = round(weighted_avg)

              # Apply general bounds for reasonableness
              project_count = max(1, min(project_count, 15))

              return project_count

      # If project section found but no clear count, return at least 1
      if project_section:
          return 1

      # No projects found
      return 0

    def _text_similarity(self, text1, text2):
        """Helper function to calculate simple text similarity"""
        # Simple word overlap score
        words1 = set(re.findall(r'\b\w{4,}\b', text1.lower()))
        words2 = set(re.findall(r'\b\w{4,}\b', text2.lower()))

        if not words1 or not words2:
            return 0

        overlap = len(words1.intersection(words2))
        return overlap / min(len(words1), len(words2))

    def extract_project_keywords(self, text):
        """Extract project keywords with improved accuracy"""
        text = self.preprocess_text(text)
        found_keywords = set()

        # Look for project sections
        project_section_patterns = [
            r'projects?(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:academic|major|minor|technical)\s+projects?(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'b\.tech\s+project(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'm\.tech\s+project(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
        ]

        project_sections = []
        for pattern in project_section_patterns:
            sections = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            project_sections.extend(sections)

        # Create a combined section text
        section_text = "\n".join(project_sections) if project_sections else text

        # Match keywords
        for keyword in self.project_keywords_list:
            if re.search(r'\b' + re.escape(keyword) + r'\b', section_text, re.IGNORECASE):
                found_keywords.add(keyword)

        # Use NLP to find additional relevant terms in project sections
        if project_sections:
            doc = nlp(section_text)
            for token in doc:
                if token.pos_ in ['NOUN', 'PROPN'] and token.text.lower() in self.project_keywords_list:
                    found_keywords.add(token.text.lower())
                # Check for bigrams and trigrams (e.g., "machine learning")
                if token.i < len(doc) - 1:
                    bigram = token.text + " " + doc[token.i + 1].text
                    if bigram.lower() in self.project_keywords_list:
                        found_keywords.add(bigram.lower())
                if token.i < len(doc) - 2:
                    trigram = token.text + " " + doc[token.i + 1].text + " " + doc[token.i + 2].text
                    if trigram.lower() in self.project_keywords_list:
                        found_keywords.add(trigram.lower())

        return list(found_keywords)

    def extract_mobile_number(self, text):
        """Extract mobile number with improved accuracy"""
        text = text.lower()

        # Look for phone/mobile/contact sections first
        contact_section_patterns = [
            r'(?:phone|mobile|contact|ph|tel|contact details)(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:^|\n).*?(?:phone|mobile|contact|ph|tel)(?:\s*:|:?\s*\n|\s*-\s*)(.*?)(?:\n|$)'
        ]

        contact_sections = []
        for pattern in contact_section_patterns:
            sections = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            contact_sections.extend(sections)

        # Search in contact sections first
        for section in contact_sections:
            for pattern in self.phone_patterns:
                phone_match = re.search(pattern, section)
                if phone_match:
                    # Clean the phone number
                    phone = re.sub(r'[^\d+]', '', phone_match.group(0))
                    return phone

        # If not found in sections, look in entire text
        for pattern in self.phone_patterns:
            phone_matches = re.findall(pattern, text)
            if phone_matches:
                # Clean the first phone number found
                phone = re.sub(r'[^\d+]', '', phone_matches[0])
                return phone

        return None

    def extract_email(self, text):
        """Extract email with improved accuracy"""
        text = text.lower()

        # Look for email/contact sections first
        contact_section_patterns = [
            r'(?:email|e-mail|mail|contact|contact details)(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:^|\n).*?(?:email|e-mail|mail)(?:\s*:|:?\s*\n|\s*-\s*)(.*?)(?:\n|$)'
        ]

        contact_sections = []
        for pattern in contact_section_patterns:
            sections = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            contact_sections.extend(sections)

        # Search in contact sections first
        for section in contact_sections:
            email_match = re.search(self.email_pattern, section)
            if email_match:
                return email_match.group(0)

        # If not found in sections, look in entire text
        email_matches = re.findall(self.email_pattern, text)
        if email_matches:
            return email_matches[0]

        return None

    def has_experience(self, text):
        """Determine if the resume shows work experience"""
        text = self.preprocess_text(text)

        # Look for experience sections
        experience_section_patterns = [
            r'(?:work\s+)?experience(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:professional|industry|job)\s+experience(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:employment|work\s+history)(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:internship|intern)(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)'
        ]

        experience_sections = []
        for pattern in experience_section_patterns:
            sections = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            experience_sections.extend(sections)

        # If we found experience sections with substantial content
        section_text = "\n".join(experience_sections)
        if section_text and len(section_text) > 50:  # Arbitrary threshold for meaningful content
            return 'Yes'

        # Look for job titles
        job_titles = [
            'engineer', 'developer', 'programmer', 'analyst', 'consultant', 'manager', 'associate',
            'intern', 'trainee', 'lead', 'architect', 'administrator', 'specialist', 'executive'
        ]

        for title in job_titles:
            # Exclude titles that are part of educational context
            pattern = r'\b' + re.escape(title) + r'\b(?!.*(?:student|pursuing|looking for|seeking))'
            if re.search(pattern, text, re.IGNORECASE):
                return 'Yes'

        # Look for company names followed by designations
        company_patterns = [
            r'(?:worked at|at|with|for)\s+([A-Z][A-Za-z]*(?:\s+[A-Z][A-Za-z]*)?)',
            r'(?:^|\n)([A-Z][A-Za-z]*(?:\s+[A-Z][A-Za-z]*)?)\s+(?:Inc\.|LLC|Ltd\.|Limited|Corp\.|Corporation)'
        ]

        for pattern in company_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                return 'Yes'

        # Look for date ranges typical of work experience
        date_range_pattern = r'(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[a-z]*[\s\'\-](?:20\d{2}|19\d{2})[\s\-\â€“\â€”]+(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|present|current)'
        if re.search(date_range_pattern, text, re.IGNORECASE):
            return 'Yes'

        # Default to No if no experience indicators found
        return 'No'

    def extract_core_computer_skills(self, text):
        """Extract core computer skills with improved accuracy"""
        text = self.preprocess_text(text)
        found_skills = set()

        # Look for skills sections
        skills_section_patterns = [
            r'(?:technical|core|computer)\s+skills(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:programming|software|technical)\s+knowledge(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)',
            r'(?:technical|core)\s+competencies(?:\s*:|:?\s*\n)(.*?)(?:\n\s*\n|\n\s*[A-Z]|\Z)'
        ]

        skills_sections = []
        for pattern in skills_section_patterns:
            sections = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)
            skills_sections.extend(sections)

        # Create a combined section text
        section_text = "\n".join(skills_sections) if skills_sections else text

        # Check each core skill category
        for skill_category, keywords in self.core_computer_skills.items():
            for keyword in keywords:
                if re.search(r'\b' + re.escape(keyword) + r'\b', section_text, re.IGNORECASE):
                    found_skills.add(skill_category)
                    break  # One match in category is enough

        # Return comma-separated list or None
        if found_skills:
            return ", ".join(sorted(found_skills))
        return None

    def evaluate_text_similarity(self, text1, text2):
        """Evaluate the similarity between two texts using TF-IDF and cosine similarity"""
        if not text1 or not text2:
            return 0.0

        # Create a TF-IDF vectorizer
        vectorizer = TfidfVectorizer(stop_words='english')

        # Transform both texts
        try:
            tfidf_matrix = vectorizer.fit_transform([text1.lower(), text2.lower()])

            # Calculate cosine similarity
            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
            return similarity
        except:
            return 0.0

    def parse_resume(self, pdf_path):
        """Parse a single resume PDF and extract only the required information"""
        text = self.extract_text_from_pdf(pdf_path)

        if not text:
            return {
                "file_name": os.path.basename(pdf_path),
                "error": "Failed to extract text from PDF"
            }

        # Extract only the required 9 columns
        gpa = self.extract_gpa(text)
        skills = self.extract_skills(text)
        branch = self.extract_branch(text)
        project_count = self.count_projects(text)
        project_keywords = self.extract_project_keywords(text)
        mobile_number = self.extract_mobile_number(text)
        email = self.extract_email(text)
        experience = self.has_experience(text)
        core_computer_skills = self.extract_core_computer_skills(text)

        return {
            "file_name": os.path.basename(pdf_path),
            "CPI/GPA": gpa,
            "Skills": skills,
            "Branch": branch,
            "No_of_Projects": project_count,
            "Project_Keywords": project_keywords,
            "Mobile_Number": mobile_number,
            "Email_ID": email,
            "Experience": experience,
            "Core_Computer_Skills": core_computer_skills
        }

    def parse_resumes_in_directory(self, directory_path, output_path=None):
        """Parse all PDF resumes in a directory and save results to CSV/Excel"""
        if not os.path.exists(directory_path):
            raise ValueError(f"Directory not found: {directory_path}")

        results = []
        pdf_files = [f for f in os.listdir(directory_path) if f.lower().endswith('.pdf')]

        if not pdf_files:
            print(f"No PDF files found in {directory_path}")
            return None

        for pdf_file in pdf_files:
            pdf_path = os.path.join(directory_path, pdf_file)
            try:
                result = self.parse_resume(pdf_path)
                results.append(result)
                print(f"Processed: {pdf_file}")
            except Exception as e:
                print(f"Error processing {pdf_file}: {e}")
                results.append({
                    "file_name": pdf_file,
                    "error": str(e)
                })

        # Convert results to DataFrame
        df = pd.DataFrame(results)

        # Clean up DataFrame
        if 'Skills' in df.columns:
            df['Skills'] = df['Skills'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)

        if 'Project_Keywords' in df.columns:
            df['Project_Keywords'] = df['Project_Keywords'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)

        # Save results if output path provided
        if output_path:
            if output_path.lower().endswith('.csv'):
                df.to_csv(output_path, index=False)
                print(f"Results saved to {output_path}")
            elif output_path.lower().endswith(('.xls', '.xlsx')):
                df.to_excel(output_path, index=False)
                print(f"Results saved to {output_path}")
            else:
                df.to_csv(output_path + '.csv', index=False)
                print(f"Results saved to {output_path}.csv")

        return df

# Example usage
def main():
    # Initialize parser
    parser = EnhancedResumeParser()

    # Set the resume directory path
    resume_dir = "/content/resume"  # Update this to your resume directory path

    # Parse all resumes and save to CSV
    results_df = parser.parse_resumes_in_directory(resume_dir, "parsed_resumes.csv")

    # Display results
    if results_df is not None:
        print("\nResume parsing complete. Results preview:")
        print(results_df[["file_name", "CPI/GPA", "Skills", "Branch", "No_of_Projects",
                         "Project_Keywords", "Mobile_Number", "Email_ID",
                         "Experience", "Core_Computer_Skills"]].head())

if __name__ == "__main__":
    main()

